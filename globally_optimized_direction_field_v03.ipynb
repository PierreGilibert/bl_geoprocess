{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bpy\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "import os\n",
    "import mathutils\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "import bmesh\n",
    "import cmath\n",
    "import scipy.sparse\n",
    "import scipy.linalg\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from line_profiler import profile\n",
    "\n",
    "from mathutils import Vector, Matrix\n",
    "from mathutils.bvhtree import BVHTree\n",
    "\n",
    "# install packages : \"C:\\Users\\Pierre.Gilibert\\OneDrive - ARVERNE\\Bureau\\blender-4.3.1-windows-x64\\4.3\\python\\bin\\python.exe\" -m pip install scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FINISHED'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDER = \"C:\\\\Users\\\\pierr\\\\Documents\\\\Blender\\\\GeometryProcessing_Python\\\\\"\n",
    "FOLDER = \"C:\\\\Users\\\\Pierre.Gilibert\\\\OneDrive - ARVERNE\\\\Documents\\\\Divers\\\\blender\"\n",
    "bpy.ops.wm.open_mainfile(filepath=os.path.join(FOLDER, \"blender_notebook_v01.blend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SectionIntegrals:\n",
    "    \"\"\"\n",
    "    Class to compute integrals (Dirichlet and Mass integrals) using Chebyshev series and direct evaluations.\n",
    "    \"\"\"\n",
    "    # Machine constants (IEEE double-precision)\n",
    "    MACH = [\n",
    "        2.2250738585072014e-308,  # Smallest positive number\n",
    "        1.7976931348623157e+308,  # Largest representable number\n",
    "        1.1102230246251565e-16,   # Machine epsilon\n",
    "        2.2204460492503131e-16,   # Largest relative spacing\n",
    "        3.0102999566398120e-01    # log10(2)\n",
    "    ]\n",
    "\n",
    "    # Chebyshev coefficients (Placeholder: fill with actual data)\n",
    "    S11R = [ 0.0448875760891932036595562553276, 0.0278480909574822965157922173757, 0.00394490790249120295818107628687, -0.00157697939158619172562804651751, \n",
    "            -0.0000886578217796691901712579357311,0.0000301708056772263120428135787035, 9.521839632337438230089618156e-7,-3.00028307455805582080773625835e-7, \n",
    "            -6.14917009583473496433650831019e-9,1.85133588988085286010092653662e-9, 2.67848449041765751590373973224e-11,-7.82394575359355297437491915705e-12, \n",
    "            -8.44240072511090922609176843848e-14,2.41333276776166240844516922196e-14, 2.02015531985181413114834031833e-16,-5.68171271075270422851146478874e-17, \n",
    "            -3.80082421064644521052871349836e-19,1.05551739229841670238163200361e-19, 5.7758422925275435667221605993e-22,-1.58774695838716531303310462626e-22, \n",
    "            -7.24181766014636685673730787292e-25]  \n",
    "    S11I = [0.100116671557942715638078149123,0.0429600096728215971268270800599, -0.00799014859477407505770275088389,-0.000664114111384495427035329182866, \n",
    "            0.000240714510952202000864758517061,9.89085259369337382687437812294e-6, -3.22040860178194578481012477174e-6,-8.08401148192350365282200249069e-8,\n",
    "              2.48351290049260966544658921605e-8,4.24154988067028660399867468349e-10, -1.25611378629704490237955971836e-10,-1.56053077919196502557674988724e-12, \n",
    "              4.50565044006801278137904597946e-13,4.2641179237225098728291226479e-15, -1.2084245714879456268965803807e-15,-9.01338537885038989528688031325e-18, \n",
    "              2.5180796700698002962991581923e-18,1.51955263898294940481729370636e-20, -4.19737873024216866691628952458e-21,-2.092488792285595339755624521e-23, \n",
    "              5.72708467031136321701747126611e-24]\n",
    "    S12R = [-0.376145877558191778393359413441,0.0775244431850198578126067647425, 0.0120396593748540634695397747695,-0.00385683684390247509721340352427, \n",
    "            -0.000232359275790231209370627606991,0.0000697318379146209092637310696007, 2.32354473986257272021507575389e-6,-6.71692140309360615694979580992e-7, \n",
    "            -1.43946361256617673523038166877e-8,4.06087820907414336567714443732e-9, 6.10183339004616075548375321861e-11,-1.69196418769523832825063863136e-11, \n",
    "            -1.88669746820541798989965091628e-13,5.16473095452962111184823547686e-14, 4.45066881692009291504139737861e-16,-1.20625107617859803735741992452e-16, \n",
    "            -8.28193837331508300767103116139e-19,2.22680015825230528892642524445e-19, 1.24755889505424049389100515561e-21,-3.33254971913153176741833960484e-22,\n",
    "              -1.55307002839777371508497520751e-24]\n",
    "    S12I = [0.0527472790869782317601048210983,0.00823962722148093961886198320927, -0.0205185842051817330153151013327,-0.00184683218270819613487368071941, \n",
    "            0.000569681886932212757533488372406,0.0000248774530818801164177266528608, -7.31121019876580624171992432347e-6,-1.92744564223806538367454388776e-7, \n",
    "            5.49794278719049727550379096876e-8,9.78237385539447442446850072421e-10, -2.7341624177723508216430132999e-10,-3.51839815887772323640101921381e-12, \n",
    "            9.68934411607055794052256859665e-13,9.45703963505047353201918875825e-15, -2.57516976113400217760868402425e-15,-1.97419921753098238455550504742e-17, \n",
    "            5.32820017906655555903355375475e-18,3.29581793797656865402793252539e-20, -8.83137325823594007269279476114e-21,-4.50279718100548728336329365981e-23, \n",
    "            1.19941679774924468309434420379e-23]\n",
    "    M12R = [0.148523151773238914750879360089,-0.0117856118001224048185631301904, -0.00248887208039014371691400683052,0.000250045060357076469386198883676, \n",
    "            0.0000227217776065076434637230864113,-2.48764935230787745662127026799e-6, -1.32138506847814502856384193414e-7,1.50966754393693942843767293542e-8, \n",
    "            5.3472999553162661403204445045e-10,-6.26136041009708550772228055719e-11, -1.59574066624737000616598104732e-12,1.89788785691219687197167013023e-13, \n",
    "            3.66030609080549274006207730375e-15,-4.39955659500182569051978906011e-16, -6.65848768159000092224193226014e-18,8.06343127453005031535923212263e-19, \n",
    "            9.84397490339224661524630997726e-21,-1.19869887155210161836484730378e-21, -1.20634550494837590549640883469e-23,1.47512193662595435067359954287e-24, \n",
    "            1.24549093756962710863096766634e-26]\n",
    "    M12I = [-0.0454399665519585306943416687117,-0.0210517666740874019203591488894, 0.00194647501081621201871675259482,0.000253466068123907163346571754613, \n",
    "            -0.0000268083453427538717591876419304,-1.82138740336918117478832696004e-6, 2.04357511048425337951376869602e-7,8.75944656915074206478854298947e-9, \n",
    "            -1.01466837126303146739791005703e-9,-3.02573132377805421636557302451e-11, 3.57358222114420372764650037191e-12,7.88121312149152771558608913996e-14, \n",
    "            -9.42758576193708862552405242331e-15,-1.60439904050827900099939709069e-16, 1.93624791035947590366500765061e-17,2.62394448214143482490534256935e-19, \n",
    "            -3.18700789496399461681365308408e-20,-3.52400207248027768109209530864e-22, 4.30074555255053206057921088056e-23,3.95655079023456015736315286131e-25, \n",
    "            -4.84642137915095135859812028886e-26]\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        # Number of terms initialized for each Chebyshev series\n",
    "        self.ns11r = self.ns11i = 0\n",
    "        self.ns12r = self.ns12i = 0\n",
    "        self.nm12r = self.nm12i = 0\n",
    "\n",
    "    def inits(self, series, eta):\n",
    "        \"\"\"\n",
    "        Determine the number of terms required to achieve precision `eta`.\n",
    "        \"\"\"\n",
    "        err = 0.0\n",
    "        n = len(series)\n",
    "        for i in range(n - 1, -1, -1):\n",
    "            err += abs(series[i])\n",
    "            if err > eta:\n",
    "                return i + 1\n",
    "        return 0\n",
    "\n",
    "    def csevl(self, x, cs, n):\n",
    "        \"\"\"\n",
    "        Evaluate Chebyshev series at normalized value x in [-1, 1].\n",
    "        \"\"\"\n",
    "        b0, b1, b2 = 0.0, 0.0, 0.0\n",
    "        twox = 2 * x\n",
    "        for i in range(n - 1, -1, -1):\n",
    "            b2, b1 = b1, b0\n",
    "            b0 = twox * b1 - b2 + cs[i]\n",
    "        return (b0 - b2) / 2\n",
    "\n",
    "    def s11(self, t):\n",
    "        \"\"\"\n",
    "        Compute s11 integral using Chebyshev series.\n",
    "        \"\"\"\n",
    "        if not self.ns11r:\n",
    "            self.ns11r = self.inits(self.S11R, self.MACH[2] / 10)\n",
    "            self.ns11i = self.inits(self.S11I, self.MACH[2] / 10)\n",
    "        real = self.csevl(t, self.S11R, self.ns11r)\n",
    "        imag = self.csevl(t, self.S11I, self.ns11i)\n",
    "        return complex(real, imag)\n",
    "\n",
    "    def s12(self, t):\n",
    "        \"\"\"\n",
    "        Compute s12 integral using Chebyshev series.\n",
    "        \"\"\"\n",
    "        if not self.ns12r:\n",
    "            self.ns12r = self.inits(self.S12R, self.MACH[2] / 10)\n",
    "            self.ns12i = self.inits(self.S12I, self.MACH[2] / 10)\n",
    "        real = self.csevl(t, self.S12R, self.ns12r)\n",
    "        imag = self.csevl(t, self.S12I, self.ns12i)\n",
    "        return complex(real, imag)\n",
    "\n",
    "    def dirichlet_ii(self, s, gjj, gjk, gkk):\n",
    "        return .25 * ((gjj - 2 * gjk + gkk)+ s * s * (gjj + gjk + gkk) / 90)\n",
    "\n",
    "    def dirichlet_ij_direct(self, s, gii, gij, gjj):\n",
    "        \"\"\"\n",
    "        Direct evaluation of Dirichlet integral for large s.\n",
    "        \"\"\"\n",
    "        s2 = s * s\n",
    "        _is = 1j*s\n",
    "        _is3 = _is * s2\n",
    "        s4 = s2 * s2\n",
    "        eis = np.cos(s) + 1j * np.sin(s)\n",
    "        return ((3*gii + 4*gij + 3*gjj) + _is*(gii + gij + gjj) - _is3*gij/6 + eis*(-(3*gii + 4*gij + 3*gjj) + _is*(2*gii + 3*gij + 2*gjj) + s2*(gii + 2*gij + gjj)/2))/s4 + (gii - 2*gij + gjj)/24 - _is*(gii - 2*gij + gjj)/60\n",
    "\n",
    "        return complex(0.0, 0.0)  # Replace with actual direct computation\n",
    "\n",
    "    def dirichlet_ij(self, s, gii, gij, gjj):\n",
    "        \"\"\"\n",
    "        Compute Dirichlet integral.\n",
    "        \"\"\"\n",
    "        if abs(s) > np.pi:\n",
    "            return self.dirichlet_ij_direct(s, gii, gij, gjj)\n",
    "        t = s * 2 / np.pi - 1 if s > 0 else -s * 2 / np.pi - 1\n",
    "        result = ((gii + gjj) * self.s11(t) + gij * self.s12(t))\n",
    "        return result.conjugate() if s > 0 else result\n",
    "\n",
    "    def mass_ii(self):\n",
    "        \"\"\"\n",
    "        Compute MassII integral.\n",
    "        \"\"\"\n",
    "        return 1 / 6.0\n",
    "\n",
    "    def mass_ij_direct(self, s):\n",
    "        \"\"\"\n",
    "        Direct evaluation of MassIJ integral for large s.\n",
    "        \"\"\"\n",
    "        s2 = s * s\n",
    "        s4 = s2 * s2\n",
    "        is_ = complex(0, s)\n",
    "        is3 = complex(0, s * s2)\n",
    "        return (6 * np.exp(is_) - 6 - 6 * is_ + 3 * s2 + is3) / (3 * s4)\n",
    "\n",
    "    def mass_ij(self, s):\n",
    "        \"\"\"\n",
    "        Compute MassIJ integral.\n",
    "        \"\"\"\n",
    "        if abs(s) > np.pi:\n",
    "            return self.mass_ij_direct(s)\n",
    "        t = s / np.pi * 2 - 1 if s > 0 else -s / np.pi * 2 - 1\n",
    "        return self.s12(t).conjugate() if s > 0 else self.s12(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyBezier:\n",
    "    def __init__(self, spline):\n",
    "        self.spline = spline\n",
    "\n",
    "\n",
    "    def _retrieve_segment_and_local_coordinate_at(self, t):\n",
    "        # Ensure t is within [0, 1]\n",
    "        t = max(0.0, min(1.0, t))\n",
    "\n",
    "        # Total number of segments (n - 1 control points)\n",
    "        n_segments = len(self.spline.bezier_points) - 1\n",
    "        if n_segments < 1:\n",
    "            raise ValueError(\"The spline must have at least two bezier points.\")\n",
    "\n",
    "        # Determine which segment the parameter t falls into\n",
    "        segment_index = int(t * n_segments)\n",
    "        segment_index = min(segment_index, n_segments - 1)  # Clamp to valid index\n",
    "\n",
    "        # Compute local parameter s in the segment\n",
    "        s = (t - segment_index / n_segments) * n_segments\n",
    "\n",
    "        # Retrieve the control points for the segment\n",
    "        pA = self.spline.bezier_points[segment_index].co\n",
    "        hA = self.spline.bezier_points[segment_index].handle_right\n",
    "        pB = self.spline.bezier_points[segment_index + 1].co\n",
    "        hB = self.spline.bezier_points[segment_index + 1].handle_left\n",
    "        return s, pA, hA, pB, hB\n",
    "\n",
    "\n",
    "    def evaluate(self, t):\n",
    "        \"\"\"\n",
    "        Evaluate the position on the Bezier curve at parameter t (0 <= t <= 1).\n",
    "\n",
    "        Parameters:\n",
    "        t (float): A parameter between 0 and 1.\n",
    "\n",
    "        Returns:\n",
    "        Vector: The 3D coordinate of the point at t.\n",
    "        \"\"\"\n",
    "        s, pA, hA, pB, hB = self._retrieve_segment_and_local_coordinate_at(t)\n",
    "\n",
    "        # Compute p(s) using the cubic Bezier formula\n",
    "        p_s = ((1 - s) ** 3) * pA + \\\n",
    "              3 * ((1 - s) ** 2) * s * hA + \\\n",
    "              3 * (1 - s) * (s ** 2) * hB + \\\n",
    "              (s ** 3) * pB\n",
    "\n",
    "        return p_s\n",
    "\n",
    "\n",
    "    def evaluate_derivative(self, t):\n",
    "        \"\"\"\n",
    "        Compute the tangent (derivative) of the Bezier curve at parameter t.\n",
    "\n",
    "        Parameters:\n",
    "        t (float): A parameter between 0 and 1.\n",
    "\n",
    "        Returns:\n",
    "        Vector: The 3D tangent vector at t.\n",
    "        \"\"\"\n",
    "        s, pA, hA, pB, hB = self._retrieve_segment_and_local_coordinate_at(t)\n",
    "        p_prime_s = -3 * ((1 - s) ** 2) * pA + \\\n",
    "                     3 * ((1 - s) ** 2 - 2 * (1 - s) * s) * hA + \\\n",
    "                     3 * (2 * (1 - s) * s - s ** 2) * hB + \\\n",
    "                     3 * (s ** 2) * pB\n",
    "        return p_prime_s.normalized()\n",
    "\n",
    "\n",
    "\n",
    "def wrap_spline(spline):\n",
    "    \"\"\"Wrap a spline object in the appropriate class.\"\"\"\n",
    "    if spline.type == 'BEZIER':\n",
    "        return MyBezier(spline)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported spline type: {spline.type}\")\n",
    "\n",
    "\n",
    "    \n",
    "def load_guide_curves(collection_name):\n",
    "    \"\"\"\n",
    "    Load all Bezier curves from the specified collection.\n",
    "\n",
    "    Parameters:\n",
    "    collection_name (str): The name of the collection containing the Bezier curves.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of curve objects (bpy.types.Curve) representing the Bezier curves.\n",
    "    \"\"\"\n",
    "    curves = []\n",
    "    \n",
    "    # Get the collection\n",
    "    if collection_name in bpy.data.collections:\n",
    "        collection = bpy.data.collections[collection_name]\n",
    "        \n",
    "        # Iterate through objects in the collection\n",
    "        for obj in collection.objects:\n",
    "            if obj.type == 'CURVE':             \n",
    "                curves.append(obj)\n",
    "    else:\n",
    "        print(f\"Collection '{collection_name}' not found.\")\n",
    "    \n",
    "    return curves\n",
    "\n",
    "def curve_2_polyline(curve, sampling_step):\n",
    "    \"\"\"\n",
    "    Discretize a curve into a polyline by sampling points along its length.\n",
    "\n",
    "    Parameters:\n",
    "    curve (bpy.types.Object): The curve object to discretize.\n",
    "    sampling_step (float): The distance between sampled points.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tuples, each containing (point, tangent), where:\n",
    "          - point (Vector): The position of the sampled point.\n",
    "          - tangent (Vector): The tangent at the sampled point.\n",
    "    \"\"\"\n",
    "    polyline = []\n",
    "\n",
    "    if curve.type != 'CURVE':\n",
    "        raise ValueError(\"Provided object is not a curve.\")\n",
    "\n",
    "    # Iterate through splines in the curve\n",
    "    for spline in curve.data.splines:\n",
    "        # print(spline.bezier_points)\n",
    "        for ii, p in enumerate(spline.bezier_points):\n",
    "            draw_sphere(p.co, 0.005, f\"bezier_{ii}\")\n",
    "            # print(p.handle_left, p.handle_right, p.co)\n",
    "        wrapped_spline = wrap_spline(spline)\n",
    "\n",
    "        # Estimate the number of points based on spline length\n",
    "        total_length = spline.calc_length()  # Length of the spline\n",
    "        num_points = max(2, int(total_length / sampling_step))  # Number of points\n",
    "\n",
    "        # Generate sampled points along the curve\n",
    "        for i in range(num_points):\n",
    "            t = i / (num_points - 1)  # Parameter along the curve (0 to 1)\n",
    "            point = wrapped_spline.evaluate(t)\n",
    "            # tangent = wrapped_spline.evaluate_derivative(t)\n",
    "\n",
    "            # Transform point and tangent to world coordinates\n",
    "            point_world = curve.matrix_world @ point\n",
    "            # tangent_world = curve.matrix_world.to_3x3() @ tangent\n",
    "\n",
    "            polyline.append(point_world)\n",
    "\n",
    "    return polyline\n",
    "\n",
    "def polyline_to_mesh(polyline_pts, tangents, name=\"PolylineMesh\"):\n",
    "    \"\"\"\n",
    "    Create a Blender mesh object from a polyline.\n",
    "\n",
    "    Parameters:\n",
    "    polyline_pts (list of [Vector]): A list of [point] where:\n",
    "    tangents (list of [Vector]): A list of [tangent] where:\n",
    "                                         - point (Vector): A 3D coordinate.\n",
    "                                         - tangent (Vector): A 3D tangent vector \n",
    "    name (str): The name of the created mesh object.\n",
    "\n",
    "    Returns:\n",
    "    bpy.types.Object: The created mesh object.\n",
    "    \"\"\"\n",
    "    if not polyline_pts or len(polyline_pts) < 2:\n",
    "        raise ValueError(\"Polyline must contain at least two points.\")\n",
    "\n",
    "    # Extract points from the polyline\n",
    "    # points = [p[0] for p in polyline]\n",
    "    # tangents = [p[1] for p in polyline]\n",
    "\n",
    "    # Create a new mesh and object\n",
    "    mesh = bpy.data.meshes.new(name)\n",
    "    obj = bpy.data.objects.new(name, mesh)\n",
    "\n",
    "    # Link the object to the current collection\n",
    "    bpy.context.collection.objects.link(obj)\n",
    "\n",
    "    # Create the mesh data\n",
    "    mesh.from_pydata(polyline_pts, [(i, i + 1) for i in range(len(polyline_pts) - 1)], [])\n",
    "\n",
    "    if 'tangent_at_p' in mesh.attributes:\n",
    "        mesh.attributes.remove(mesh.attributes[\"tangent_at_p\"])\n",
    "\n",
    "    attr = mesh.attributes.new(name=\"tangent_at_p\", type='FLOAT_VECTOR', domain='POINT')\n",
    "    attr.data.foreach_set('vector', np.array(tangents).flatten())\n",
    "\n",
    "    # Update the mesh to ensure it displays correctly in Blender\n",
    "    mesh.update()\n",
    "    \n",
    "    return obj\n",
    "\n",
    "def ensure_helpers_collection():\n",
    "    \"\"\"\n",
    "    Ensure that a collection named \"Helpers\" exists in the scene.\n",
    "    Returns the \"Helpers\" collection.\n",
    "    \"\"\"\n",
    "    if \"Helpers\" not in bpy.data.collections:\n",
    "        helpers_collection = bpy.data.collections.new(\"Helpers\")\n",
    "        bpy.context.scene.collection.children.link(helpers_collection)\n",
    "    return bpy.data.collections[\"Helpers\"]\n",
    "\n",
    "\n",
    "def draw_cylinder(pstart, pend, radius, name=\"Helper_Cylinder\"):\n",
    "    \"\"\"\n",
    "    Draw a cylinder using Blender's bmesh module.\n",
    "\n",
    "    Parameters:\n",
    "    pstart (Vector): The center of the bottom circular face.\n",
    "    pend (Vector): A point on the center of the top circular face.\n",
    "    radius (float): The radius of the cylinder.\n",
    "\n",
    "    Returns:\n",
    "    The Blender object representing the cylinder.\n",
    "    \"\"\"\n",
    "    # Delete all objects named \"Cylinder\" in the scene\n",
    "    for obj in bpy.data.objects:\n",
    "        if obj.name == name:\n",
    "            bpy.data.objects.remove(obj, do_unlink=True)\n",
    "    # Calculate the cylinder's length (height) and direction vector\n",
    "    direction = pend - pstart\n",
    "    height = direction.length\n",
    "\n",
    "    # Normalize the direction vector\n",
    "    direction.normalize()\n",
    "\n",
    "    # Create a new mesh and object for the cylinder\n",
    "    mesh = bpy.data.meshes.new(name)\n",
    "    obj = bpy.data.objects.new(name, mesh)\n",
    "    # bpy.context.collection.objects.link(obj)\n",
    "    # Add the object to the \"Helpers\" collection\n",
    "    helpers_collection = ensure_helpers_collection()\n",
    "    helpers_collection.objects.link(obj)\n",
    "\n",
    "    # Create a bmesh object to define geometry\n",
    "    bm = bmesh.new()\n",
    "    bmesh.ops.create_cone(\n",
    "        bm,\n",
    "        cap_ends=True,\n",
    "        segments=16,\n",
    "        radius1=radius,\n",
    "        radius2=radius/4,\n",
    "        depth=height\n",
    "    )\n",
    "\n",
    "    # Apply a transformation matrix to orient the cylinder\n",
    "    # Align the cylinder along the specified axis\n",
    "    up = Vector((0, 0, 1))\n",
    "    rot_axis = up.cross(direction)\n",
    "    if rot_axis.length > 0:  # Ensure the rotation axis is valid\n",
    "        rot_axis.normalize()\n",
    "        angle = up.angle(direction)\n",
    "        rot_matrix = Matrix.Rotation(angle, 4, rot_axis)\n",
    "\n",
    "        bmesh.ops.rotate(bm, verts=bm.verts, cent=(0, 0, 0), matrix=rot_matrix)\n",
    "\n",
    "    # Translate the cylinder to the starting position\n",
    "    translation = bmesh.ops.translate(bm, verts=bm.verts, vec=(pstart+pend)/2)\n",
    "\n",
    "    # Write the bmesh data to the mesh\n",
    "    bm.to_mesh(mesh)\n",
    "    bm.free()\n",
    "\n",
    "\n",
    "def draw_sphere(centre, radius, name):\n",
    "    \"\"\"\n",
    "    Draw a sphere using Blender's bmesh module.\n",
    "\n",
    "    Parameters:\n",
    "    centre (Vector): The center of the sphere.\n",
    "    radius (float): The radius of the sphere.\n",
    "\n",
    "    Returns:\n",
    "    The Blender object representing the sphere.\n",
    "    \"\"\"\n",
    "    # Delete all objects named \"Sphere\" in the scene\n",
    "    for obj in bpy.data.objects:\n",
    "        if obj.name == name:\n",
    "            bpy.data.objects.remove(obj, do_unlink=True)\n",
    "\n",
    "    # Create a new mesh and object for the sphere\n",
    "    mesh = bpy.data.meshes.new(name)\n",
    "    obj = bpy.data.objects.new(name, mesh)\n",
    "    # bpy.context.collection.objects.link(obj)\n",
    "    # Add the object to the \"Helpers\" collection\n",
    "    helpers_collection = ensure_helpers_collection()\n",
    "    helpers_collection.objects.link(obj)\n",
    "\n",
    "    # Create a bmesh object to define geometry\n",
    "    bm = bmesh.new()\n",
    "    bmesh.ops.create_uvsphere(\n",
    "        bm,\n",
    "        u_segments=4,\n",
    "        v_segments=4,\n",
    "        radius= radius\n",
    "    )\n",
    "\n",
    "    # Translate the sphere to the specified center\n",
    "    bmesh.ops.translate(bm, verts=bm.verts, vec=centre)\n",
    "\n",
    "    # Write the bmesh data to the mesh\n",
    "    bm.to_mesh(mesh)\n",
    "    bm.free()\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def project_polyline_to_mesh(polyline, target_bmesh):\n",
    "    \"\"\"\n",
    "    Project a polyline onto the surface of a given mesh.\n",
    "\n",
    "    Parameters:\n",
    "    polyline (list of Vector): The input polyline (a list of 3D points).\n",
    "    target_bmesh (bmesh): The mesh object onto which the polyline will be projected.\n",
    "\n",
    "    Returns:\n",
    "    list of Vector: The projected polyline points.\n",
    "    \"\"\"\n",
    "    # Ensure the target object is a mesh\n",
    "    # if target_bmesh.type != 'MESH':\n",
    "    #     raise ValueError(\"Target mesh must be of type 'MESH'.\")\n",
    "\n",
    "    # Create a BVH tree for the target mesh\n",
    "    # mesh_data = target_mesh.data\n",
    "    # bm = bmesh.new()\n",
    "    # bm.from_mesh(mesh_data)\n",
    "    target_bmesh.normal_update()\n",
    "    bvh_tree = BVHTree.FromBMesh(target_bmesh)\n",
    "    # bm.free()\n",
    "\n",
    "    # Project each polyline point onto the mesh\n",
    "    projected_polyline = []\n",
    "    face_indices = []\n",
    "    for point in polyline:\n",
    "        # Find the nearest point on the mesh surface\n",
    "        location, _, index, _ = bvh_tree.find_nearest(point)\n",
    "        if location is not None:\n",
    "            projected_polyline.append(location)\n",
    "            face_indices.append(index)\n",
    "        else:\n",
    "            # If no projection is found (rare case), use the original point\n",
    "            # projected_polyline.append(point)\n",
    "            pass\n",
    "\n",
    "    return projected_polyline, face_indices\n",
    "\n",
    "def resample_polyline_1_point_per_face(polyline, face_indices):\n",
    "    \"\"\"\n",
    "    Resample the polyline to ensure there is only one point per face.\n",
    "\n",
    "    Parameters:\n",
    "    polyline (list of Vector): The projected polyline (points on the mesh).\n",
    "    face_indices (list of int): The indices of the faces the polyline points were projected onto.\n",
    "\n",
    "    Returns:\n",
    "    list of Vector: The resampled polyline with one point per face.\n",
    "    \"\"\"\n",
    "    resampled_polyline = []\n",
    "    visited_faces = []  # Track faces that have already contributed a point\n",
    "    for i, face_index in enumerate(face_indices):\n",
    "        if face_index not in visited_faces:\n",
    "            visited_faces.append(face_index)  # Mark this face as visited\n",
    "            resampled_polyline.append(polyline[i])  # Add the corresponding point\n",
    "    return resampled_polyline, visited_faces\n",
    "\n",
    "def get_tangent(polyline):\n",
    "    \"\"\"\n",
    "    Calculate the tangent vectors for each point in the polyline.\n",
    "\n",
    "    Parameters:\n",
    "    polyline (list of Vector): The polyline points.\n",
    "\n",
    "    Returns:\n",
    "    list of Vector: The tangent vectors at each point.\n",
    "    \"\"\"\n",
    "    tangents = []\n",
    "\n",
    "    for i in range(len(polyline)):\n",
    "        if i == 0:\n",
    "            # Forward difference for the first point\n",
    "            tangent = polyline[i + 1] - polyline[i]\n",
    "        elif i == len(polyline) - 1:\n",
    "            # Backward difference for the last point\n",
    "            tangent = polyline[i] - polyline[i - 1]\n",
    "        else:\n",
    "            # Central difference for all other points\n",
    "            tangent = (polyline[i + 1] - polyline[i - 1]) / 2\n",
    "\n",
    "        tangents.append(tangent.normalized())  # Normalize for unit length\n",
    "\n",
    "    return tangents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V|:3456, |E|:10368, |F|:6912\n",
      "1 curves loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rotate_coord_system_vectorized(uv, vv, nf, nv):\n",
    "    dot = np.sum(nv*nf, axis=1)\n",
    "    dot_neg = np.where(dot <= -1)[0]\n",
    "    dot = dot[:,None]\n",
    "    perp = nf - dot * nv\n",
    "    dperp = (nf + nv)/(1+dot)\n",
    "    new_uv = uv - dperp * np.sum(perp*uv, axis=1)[:,None] # u - dperp * (perp.u)\n",
    "    new_vv = vv - dperp * np.sum(perp*vv, axis=1)[:,None]\n",
    "\n",
    "    new_uv[dot_neg]=-uv[dot_neg]\n",
    "    new_uv[dot_neg]=-vv[dot_neg]\n",
    "\n",
    "    return new_uv, new_vv\n",
    "\n",
    "def project_curvature_tensor_vectorized(uf, vf, nf, old_ku, old_kuv, old_kv, up, vp, n):\n",
    "    \"\"\"\n",
    "    Perform a projection of the tensor variables to the vertex coordinate system.\n",
    "    \n",
    "    Parameters:\n",
    "    uf, vf (numpy.ndarray): Face coordinate system unit vectors.\n",
    "    nf (numpy.ndarray): Normal vector of the face.\n",
    "    old_ku, old_kuv, old_kv (float): Face curvature tensor variables.\n",
    "    up, vp (numpy.ndarray): Vertex coordinate system unit vectors.\n",
    "    n (numpy.ndarray): Normal vector of the vertex.\n",
    "    \n",
    "    Returns:\n",
    "    new_ku, new_kuv, new_kv (float): Vertex curvature tensor variables.\n",
    "    \"\"\"\n",
    "    def compute_coeff(a, b, ku, kuv, kv, c, d):\n",
    "        return ku * c * a + kuv * (a*d + b*c) + kv * d * b # [a,b] @ [[ku, kuv], [kuv, kv]] @ [[c], [d]]\n",
    "    \n",
    "    # Rotate the coordinate system\n",
    "    r_new_u, r_new_v = rotate_coord_system_vectorized(up, vp, nf, n)\n",
    "\n",
    "    u1, u2 = np.sum(r_new_u*uf, axis=1), np.sum(r_new_v*uf, axis=1)\n",
    "    v1, v2 = np.sum(r_new_u*vf, axis=1), np.sum(r_new_v*vf, axis=1)\n",
    "\n",
    "    new_ku = compute_coeff(u1, v1, old_ku, old_kuv, old_kv, u1, v1)\n",
    "    new_kuv = compute_coeff(u1, v1, old_ku, old_kuv, old_kv, u2, v2)\n",
    "    new_kv = compute_coeff(u2, v2, old_ku, old_kuv, old_kv, u2, v2)\n",
    "\n",
    "    return new_ku, new_kuv, new_kv\n",
    "\n",
    "\n",
    "class HEEdge:\n",
    "    def __init__(self, edge, face, orientation:int):\n",
    "        self.edge = edge\n",
    "        self.face = face\n",
    "        self.orientation = orientation\n",
    "        self.vertex = edge.verts[orientation] # orientation in {0,1} stating whether the self.edge is in the same (0) direction as self or the opposite (1) direction.\n",
    "        self.next = None\n",
    "        self.twin = None\n",
    "        self.angle_from_X = 0.0\n",
    "        self.transport_coeff = 0.0\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"HEedge : {self.edge} - orientation: {self.orientation}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"HEedge : {self.edge} - orientation: {self.orientation}\"\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        # Delegate attribute access to the internal bmesh instance\n",
    "        return getattr(self.edge, item)\n",
    "    \n",
    "\n",
    "class MYMesh:\n",
    "    def __init__(self):\n",
    "        self.bm = bmesh.new()\n",
    "        self.facecorners = []\n",
    "        self.vert2facecorner = {}\n",
    "        self.facecorner_attributes = {}             # facecorners attributes\n",
    "        self.vertex_attributes = {\"u\":{}, \"v\":{}}   # u,v : basis vector of the tangent plane at each vertex\n",
    "        self.edge_attributes = {}\n",
    "        self.face_attributes = {}\n",
    "        self.face_vertex_to_facecorner = {}\n",
    "        self.co = None                              # A (|V|, 3) np array where row i contains the x,y,z coordinates of the vertex indexed by i \n",
    "        self.cotan = None                           # A (3|F|,) np array where entry i is the cotangent of the angle of facecorner (loop) i\n",
    "        self.face_areas = None                      # A (|F|,) np array where entry i is the area for face i\n",
    "        self.internal_angles = None                 # A (3|F|,) np array where entry i is the angle of facecorner (loop) i\n",
    "        self.fv = None                              # A (|F|, 3) np array where row i contains the indices of the vertices of face i\n",
    "        self.heedges = []                           # List of Half edges\n",
    "        self.dict_vert2heedges = {}\n",
    "\n",
    "\n",
    "    def from_mesh(self, mesh_data):\n",
    "        \"\"\" Mimic the bmesh from_mesh function. \"\"\"\n",
    "        self.bm.from_mesh(mesh_data)\n",
    "        self.vert2facecorner = {v:[] for v in self.verts}\n",
    "        self.facecorners = []\n",
    "        for face in self.faces:\n",
    "            self.face_vertex_to_facecorner[face] = {}\n",
    "            for loop in face.loops:\n",
    "                self.vert2facecorner[loop.vert].append(loop)\n",
    "                self.facecorners.append(loop)\n",
    "                self.face_vertex_to_facecorner[face][loop.vert] = loop\n",
    "            \n",
    "        self.fv = np.array([[fc.vert.index for fc in f.loops] for f in self.faces], dtype=int) # face #f has vertex [vi, vj, vk]\n",
    "        self.co = np.array([v.co for v in self.verts])\n",
    "        \n",
    "\n",
    "    def to_mesh(self, mesh_data):\n",
    "        \"\"\" Mimic the bmesh to_mesh function. \"\"\"\n",
    "        self.bm.to_mesh(mesh_data)\n",
    "    \n",
    "    # Add any other bmesh methods as needed:\n",
    "    def free(self):\n",
    "        \"\"\" Mimic the bmesh free function. \"\"\"\n",
    "        self.bm.free()\n",
    "\n",
    "    # Add a custom method to directly access the internal bmesh:\n",
    "    def __getattr__(self, item):\n",
    "        # Delegate attribute access to the internal bmesh instance\n",
    "        return getattr(self.bm, item)\n",
    "    \n",
    "    def ensure_lookup_tables(self):\n",
    "        self.verts.ensure_lookup_table()\n",
    "        self.edges.ensure_lookup_table()\n",
    "        self.faces.ensure_lookup_table()\n",
    "\n",
    "    def create_halfedge_datastructure(self):\n",
    "        self.dict_vert2heedges = {}\n",
    "        # self.edge_attributes[\"heedges\"] = {}\n",
    "        # for e in self.edges:\n",
    "        #     self.edge_attributes[\"heedges\"][e] = []\n",
    "        self.vertex_attributes[\"hedge\"] = {}\n",
    "\n",
    "        for f in self.faces:\n",
    "            if len(f.verts) != 3:\n",
    "                raise ValueError(\"Not a triangular mesh : triangulate it beforehand !!\")\n",
    "            v_orientation = [f.verts[0].index, f.verts[1].index, f.verts[2].index]\n",
    "            face_heedges = []\n",
    "            for e in f.edges:\n",
    "                # e0, e1, e2 = f.edges[0], f.edges[1], f.edges[2]\n",
    "                v0, v1 = v_orientation.index(e.verts[0].index), v_orientation.index(e.verts[1].index)\n",
    "                orientation = 1 - ((abs(v0-v1) == 1 and v0 < v1) or (abs(v0-v1) == 2 and v0 > v1)) # 0 if the edge matches the ccw convention of the face, 1 otherwise\n",
    "                # print(e, v_orientation.index(e.verts[0].index), v_orientation.index(e.verts[1].index), orientation)\n",
    "                face_heedges.append(HEEdge(e, f, orientation))\n",
    "            he0, he1, he2 = face_heedges\n",
    "            he0.next = he1\n",
    "            he1.next = he2\n",
    "            he2.next = he0\n",
    "            self.dict_vert2heedges[(he0.vertex.index, he1.vertex.index)] = he0\n",
    "            self.dict_vert2heedges[(he1.vertex.index, he2.vertex.index)] = he1\n",
    "            self.dict_vert2heedges[(he2.vertex.index, he0.vertex.index)] = he2\n",
    "            self.heedges.append(he0)\n",
    "            self.heedges.append(he1)\n",
    "            self.heedges.append(he2)\n",
    "            self.vertex_attributes[\"hedge\"][he0.vertex] = he0\n",
    "            self.vertex_attributes[\"hedge\"][he1.vertex] = he1\n",
    "            self.vertex_attributes[\"hedge\"][he2.vertex] = he2\n",
    "            # self.edge_attributes[\"heedges\"][he0.edge] = he0\n",
    "            # self.edge_attributes[\"heedges\"][he1.edge] = he1\n",
    "            # self.edge_attributes[\"heedges\"][he2.edge] = he2\n",
    "\n",
    "        for k in self.dict_vert2heedges:\n",
    "            i0, i1 = k\n",
    "            if i0 < i1:\n",
    "                continue\n",
    "            kr = (i1, i0)\n",
    "            if kr in self.dict_vert2heedges:\n",
    "                self.dict_vert2heedges[k].twin = self.dict_vert2heedges[kr]\n",
    "                self.dict_vert2heedges[kr].twin = self.dict_vert2heedges[k]\n",
    "        \n",
    "        boundary_hedges = []\n",
    "        for e in self.edges:\n",
    "            if not e.is_boundary:\n",
    "                continue\n",
    "            i0, i1 = e.verts[0].index, e.verts[1].index\n",
    "            if (i0, i1) in self.dict_vert2heedges:\n",
    "                existing_he = self.dict_vert2heedges[(i0, i1)]\n",
    "            elif (i1, i0) in self.dict_vert2heedges:\n",
    "                existing_he = self.dict_vert2heedges[(i1, i0)]\n",
    "            else:\n",
    "                raise ValueError(f\"Unable to find an half edge between vertices {i0} and {i1}\")\n",
    "            new_he = HEEdge(e, None, 1-existing_he.orientation)\n",
    "            existing_he.twin = new_he\n",
    "            new_he.twin = existing_he\n",
    "            boundary_hedges.append(new_he)\n",
    "            self.dict_vert2heedges[(new_he.vertex.index, e.other_vert(new_he.vertex).index)] = new_he\n",
    "            self.heedges.append(new_he)\n",
    "\n",
    "        # match the boundary hedges\n",
    "        num_link_to_create = len(boundary_hedges)\n",
    "        num_link_created = 0\n",
    "        while num_link_created != num_link_to_create:\n",
    "            he = boundary_hedges[num_link_created]\n",
    "            # other_index = -1\n",
    "            for i, ohe in enumerate(boundary_hedges):\n",
    "                if ohe.vertex == he.twin.vertex:\n",
    "                    other_index = i\n",
    "                    break\n",
    "            # ohe = boundary_hedges.pop(other_index)\n",
    "            he.next = ohe\n",
    "            num_link_created+=1\n",
    "\n",
    "\n",
    "        # verification : all hedges should have a twin and a next defined\n",
    "        for k in self.dict_vert2heedges:\n",
    "            he = self.dict_vert2heedges[k]\n",
    "            if he.twin is None or he.next is None:\n",
    "                raise ValueError(f\"Unable to define a twin or a next for hedge {k} : {he}\")\n",
    "\n",
    "    def _build_d0(self):\n",
    "\n",
    "        row = np.repeat(np.arange(len(self.edges)), 2)\n",
    "        col = np.array([y for e in self.edges for y in [e.verts[0].index, e.verts[1].index]])\n",
    "        val = np.ones(len(col))\n",
    "        val[1::2] = -1\n",
    "\n",
    "        # matrix[e] = [0,0,..., 1, 0, ..., -1, ..., 0] +1 at vertex vi, -1 at vertex vj where e = [vi, vj] in that order\n",
    "        return scipy.sparse.coo_matrix((val, (row, col)), shape=(len(self.edges), len(self.verts))).tocsr()\n",
    "\n",
    "    def _build_d1(self):\n",
    "        edge_dict = {tuple(sorted([e.verts[0].index, e.verts[1].index])): i for i, e in enumerate(self.edges)}\n",
    "        vi, vj, vk = self.fv[:,0], self.fv[:,1], self.fv[:,2]\n",
    "        face_edges = np.reshape(np.vstack((vi, vj, vj, vk, vk, vi)).T, (len(self.faces), 3, 2))\n",
    "        # face_edges[f] = [[i,j], [j,k], [k, i]] (shape 3,2) with i,j,k the vertex indices of face f and [i,j], [j,k] and [k,i] the 3 ordered edges of face f\n",
    "        sorted_face_edges = np.sort(face_edges, axis=2)\n",
    "        val = np.any(sorted_face_edges == face_edges, axis=2)*2-1 # +1 if edge in correct orientation, -1 otherwise\n",
    "        col = np.array([edge_dict[tuple(e)] for e in sorted_face_edges.reshape((-1,2))])\n",
    "        row = np.repeat(np.arange(len(self.faces)), 3)\n",
    "        # matrix[f] = [0, 0,... , +-1, ..., +-1, ..., +-1, ..., 0] non 0 at ei, ej, ek where f.edges = [ei, ej, ek] and +-1 depending on whether the vertices of the ei, ej, ek are in the sorted order or not \n",
    "        return scipy.sparse.coo_matrix((val.ravel(), (row, col)), shape=(len(self.faces), len(self.edges))).tocsr()\n",
    "\n",
    "    def _build_hodge0(self, inverse=False):\n",
    "        if not \"area\" in self.vertex_attributes:\n",
    "            self._calculate_vertex_area()\n",
    "        vertex_areas = self.vertex_attributes[\"area\"]\n",
    "        N = len(self.verts)\n",
    "        row = np.arange(N)\n",
    "        if inverse:\n",
    "            return scipy.sparse.coo_matrix((1/vertex_areas, (row, row)), shape=(N, N))\n",
    "        else:\n",
    "            return scipy.sparse.coo_matrix((vertex_areas, (row, row)), shape=(N, N)) # dual / primal with primal = area of vertex = 1 by convention\n",
    "\n",
    "    def _build_hodge1(self, inverse=False):\n",
    "        edge_vertex = np.array([[e.verts[0].index, e.verts[1].index] for e in self.edges])\n",
    "        edge_face_areas = np.zeros(len(self.edges))\n",
    "        for e in self.edges:\n",
    "            s = 0\n",
    "            for f in e.link_faces:\n",
    "                s += self.face_areas[f.index]\n",
    "            edge_face_areas[e.index] = s\n",
    "\n",
    "        edge_len = np.linalg.norm(self.co[edge_vertex[:,1]] - self.co[edge_vertex[:,0]], axis=1)\n",
    "        # dual_edge_lengths = edge_face_areas / edge_len\n",
    "\n",
    "        N = len(self.edges)\n",
    "        row = np.arange(N)\n",
    "        # return edge_len / edge_face_areas\n",
    "        if inverse:\n",
    "            return scipy.sparse.coo_matrix((edge_len / edge_face_areas, (row, row)), shape=(N, N))\n",
    "        else:\n",
    "            return scipy.sparse.coo_matrix((edge_face_areas / edge_len, (row, row)), shape=(N, N))\n",
    "\n",
    "    def _build_hodge2(self, inverse=False):\n",
    "        if not \"area\" in self.vertex_attributes:\n",
    "            self._calculate_vertex_area()\n",
    "\n",
    "        N = len(self.faces)\n",
    "        row = np.arange(N)\n",
    "        primal_areas = self.face_areas\n",
    "\n",
    "        dual_areas = 1 #\n",
    "\n",
    "        # fc_area = np.array([[self.facecorner_attributes[\"area\"][self.face_vertex_to_facecorner[f][v].index] for f in self.faces for v in f.verts]]).reshape((-1,3))\n",
    "        # weights = fc_area / self.face_areas[:,None]\n",
    "        # vertex_area = self.vertex_attributes[\"area\"][self.fv.ravel()].reshape((-1,3))\n",
    "        # dual_areas = weights*vertex_area\n",
    "        # dual_areas = dual_areas[:,0] + dual_areas[:,1] + dual_areas[:,2]\n",
    "        if inverse:\n",
    "            return scipy.sparse.coo_matrix((primal_areas/dual_areas, (row, row)), shape=(N, N))\n",
    "        else:\n",
    "            return scipy.sparse.coo_matrix((dual_areas/primal_areas, (row, row)), shape=(N, N))\n",
    "\n",
    "\n",
    "    def construct_dec_operators(self, inverse_hodge0=False, inverse_hodge1=False, inverse_hodge2=False):\n",
    "        \"\"\"\n",
    "        Constructs discrete exterior derivative operators (d0, d1) and\n",
    "        Hodge star matrices (hodge0, hodge1, hodge2).\n",
    "        \"\"\"\n",
    "        d0 = self._build_d0()\n",
    "        d1 = self._build_d1()\n",
    "        hodge0 = self._build_hodge0(inverse=inverse_hodge0)\n",
    "        hodge1 = self._build_hodge1(inverse=inverse_hodge1)\n",
    "        hodge2 = self._build_hodge2(inverse=inverse_hodge2)\n",
    "        \n",
    "        return d0, d1, hodge0, hodge1, hodge2\n",
    "\n",
    "    def vector_field_to_1form(self, vector_field):\n",
    "        \"\"\"\n",
    "        Projects a vertex-based tangent vector field onto a discrete 1-form on edges.\n",
    "\n",
    "        Parameters:\n",
    "        - vector_field: Nx3 numpy array, the tangent vector field at each vertex.\n",
    "\n",
    "        Returns:\n",
    "        - one_form: Mx1 numpy array, the discrete 1-form (edge-based representation).\n",
    "        \"\"\"\n",
    "        \n",
    "        edge_vertex = np.array([[e.verts[0].index, e.verts[1].index] for e in self.edges])\n",
    "        edge_dir = self.co[edge_vertex[:,1]] - self.co[edge_vertex[:,0]]\n",
    "        ui = vector_field[edge_vertex[:,0]]\n",
    "        uj = vector_field[edge_vertex[:,1]]\n",
    "        u_edge = 0.5 * (ui+uj)\n",
    "        dot = np.einsum('ij,ij->i', u_edge, edge_dir) # fast dot product \n",
    "        return dot/np.linalg.norm(edge_dir, axis=1)\n",
    "    \n",
    "    def one_form_to_vector_field(self, one_form):\n",
    "        \"\"\"\n",
    "        Maps a discrete 1-form (edge-based representation) back to a vertex-based tangent vector field.\n",
    "\n",
    "        Parameters:\n",
    "        - one_form: Mx1 numpy array, the discrete 1-form values on edges.\n",
    "\n",
    "        Returns:\n",
    "        - vector_field: Nx3 numpy array, the tangent vector field at each vertex.\n",
    "        \"\"\"\n",
    "\n",
    "        edge_vertex = np.array([[e.verts[0].index, e.verts[1].index] for e in self.edges])\n",
    "        edge_dir = self.co[edge_vertex[:,1]] - self.co[edge_vertex[:,0]]\n",
    "        edge_dir = edge_dir / np.linalg.norm(edge_dir, axis=1)[:,None]\n",
    "        contribution = one_form[:,None] * edge_dir\n",
    "\n",
    "        row = np.repeat(np.arange(len(self.edges)),2).astype(int)\n",
    "        col = edge_vertex.ravel().astype(int)\n",
    "        val = np.ones(2 * len(self.edges))\n",
    "\n",
    "        adjacency_matrix = scipy.sparse.coo_matrix((val, (row, col)))\n",
    "\n",
    "        vertex_contributions = adjacency_matrix.T @ contribution  # Sum contributions per vertex\n",
    "        vertex_edge_counts = adjacency_matrix.sum(axis=0).A1  # Number of edges per vertex (1D array)\n",
    "\n",
    "        return vertex_contributions / vertex_edge_counts[:,None]\n",
    "\n",
    "    def _calculate_corner_area(self):\n",
    "        nfaces = len(self.faces)\n",
    "        ffc = np.arange(3*nfaces).reshape((nfaces, 3)) # face corner index : face #f has corners [i, j, k];\n",
    "        angles = self.internal_angles[ffc] # array of alpha_i, alpha_j, alpha_k\n",
    "        eij = self.co[self.fv[:,1]] - self.co[self.fv[:,0]] # edges\n",
    "        ejk = self.co[self.fv[:,2]] - self.co[self.fv[:,1]]\n",
    "        eki = self.co[self.fv[:,0]] - self.co[self.fv[:,2]]\n",
    "        lij2 = eij[:,0]*eij[:,0] + eij[:,1]*eij[:,1] + eij[:,2]*eij[:,2] # squared lengths of the edges\n",
    "        ljk2 = ejk[:,0]*ejk[:,0] + ejk[:,1]*ejk[:,1] + ejk[:,2]*ejk[:,2]\n",
    "        lki2 = eki[:,0]*eki[:,0] + eki[:,1]*eki[:,1] + eki[:,2]*eki[:,2]\n",
    "\n",
    "        # in case triangle i,j,k is non obtuse (all its angles are < pi/2) then this is the area of each face corner\n",
    "        non_obtuse_area_i = 0.125 * (lij2 * self.cotan[ffc[:,2]] + lki2 * self.cotan[ffc[:,1]])\n",
    "        non_obtuse_area_j = 0.125 * (ljk2 * self.cotan[ffc[:,0]] + lij2 * self.cotan[ffc[:,2]])\n",
    "        non_obtuse_area_k = 0.125 * (lki2 * self.cotan[ffc[:,1]] + ljk2 * self.cotan[ffc[:,0]])\n",
    "\n",
    "        facecorners_areas = np.zeros(3*nfaces).reshape((nfaces, 3))\n",
    "        # check whether the angles are less than pi/2\n",
    "        small_angle_bool = angles < np.pi/2\n",
    "        big_angle_bool = ~small_angle_bool\n",
    "        # True for all corners of triangle i,j,k ==> use the non_obtuse_area\n",
    "        non_obtuse_bool = np.logical_and(small_angle_bool[:,0], np.logical_and(small_angle_bool[:,1], small_angle_bool[:,2]))\n",
    "        facecorners_areas[non_obtuse_bool, 0] = non_obtuse_area_i[non_obtuse_bool]\n",
    "        facecorners_areas[non_obtuse_bool, 1] = non_obtuse_area_j[non_obtuse_bool]\n",
    "        facecorners_areas[non_obtuse_bool, 2] = non_obtuse_area_k[non_obtuse_bool]\n",
    "        # False for corner p in {i,j,k}: use half the face area for p and a quarter for the two others corners\n",
    "        facecorners_areas[big_angle_bool[:,0]] = self.face_areas[big_angle_bool[:,0]][:,None] * np.array([[0.5, 0.25, 0.25]])\n",
    "        facecorners_areas[big_angle_bool[:,1]] = self.face_areas[big_angle_bool[:,1]][:,None] * np.array([[0.25, 0.5, 0.25]])\n",
    "        facecorners_areas[big_angle_bool[:,2]] = self.face_areas[big_angle_bool[:,2]][:,None] * np.array([[0.25, 0.25, 0.5]])\n",
    "\n",
    "        self.facecorner_attributes[\"area\"] = facecorners_areas.ravel()\n",
    "\n",
    "    def _calculate_corner_angles_and_face_areas(self):\n",
    "\n",
    "        vi = self.co[self.fv[:,0]]\n",
    "        vj = self.co[self.fv[:,1]]\n",
    "        vk = self.co[self.fv[:,2]]\n",
    "\n",
    "        eij, ejk, eki = vj-vi, vk-vj, vi-vk\n",
    "        lij2 = eij[:,0]*eij[:,0] + eij[:,1]*eij[:,1] + eij[:,2]*eij[:,2]\n",
    "        ljk2 = ejk[:,0]*ejk[:,0] + ejk[:,1]*ejk[:,1] + ejk[:,2]*ejk[:,2]\n",
    "        lki2 = eki[:,0]*eki[:,0] + eki[:,1]*eki[:,1] + eki[:,2]*eki[:,2]\n",
    "        lij, ljk, lki = np.sqrt(lij2), np.sqrt(ljk2), np.sqrt(lki2)\n",
    "\n",
    "        s = 0.5 * (lij + ljk + lki) # half perimeter of every triangle\n",
    "        self.face_areas = np.sqrt(s * (s - lij) * (s - ljk) * (s - lki)) # Heron's formula for the area of the triangles\n",
    "        \n",
    "        q_i = -ljk2 + lij2 + lki2\n",
    "        q_j = -lki2 + ljk2 + lij2\n",
    "        q_k = -lij2 + lki2 + ljk2\n",
    "\n",
    "        denom_inv = 1/(4*self.face_areas)\n",
    "        self.cotan = np.zeros(3*len(bm.faces))\n",
    "        self.cotan[0::3] = q_i*denom_inv\n",
    "        self.cotan[1::3] = q_j*denom_inv\n",
    "        self.cotan[2::3] = q_k*denom_inv\n",
    "\n",
    "        self.internal_angles = np.zeros(3*len(bm.faces))\n",
    "        self.internal_angles[0::3] = np.arccos(np.clip(q_i / (2*lij * lki), -1, 1))\n",
    "        self.internal_angles[1::3] = np.arccos(np.clip(q_j / (2*ljk * lij), -1, 1))\n",
    "        self.internal_angles[2::3] = np.arccos(np.clip(q_k / (2*lki * ljk), -1, 1))\n",
    "\n",
    "    def calculate_required_data(self):\n",
    "\n",
    "        self._calculate_corner_angles_and_face_areas()\n",
    "        self._calculate_corner_area()\n",
    "        self._calculate_vertex_area()\n",
    "        self._calculate_vertex_basis()\n",
    "\n",
    "    def _calculate_vertex_area(self):\n",
    "        # self.vertex_attributes[\"area\"] = np.array([np.sum([self.facecorner_attributes[\"area\"][fc.index] for fc in self.vert2facecorner[v]]) for v in self.verts])\n",
    "        if not \"area\" in self.facecorner_attributes:\n",
    "            self._calculate_corner_area()\n",
    "            \n",
    "        val = []\n",
    "        for v in self.verts:\n",
    "            s = 0\n",
    "            for fc in self.vert2facecorner[v]:\n",
    "                s += self.facecorner_attributes[\"area\"][fc.index]\n",
    "            val.append(s)\n",
    "        self.vertex_attributes[\"area\"] = np.array(val)\n",
    "            \n",
    "    def _calculate_vertex_basis(self):\n",
    "        eij = np.array([v.link_edges[0].other_vert(v).co - v.co for v in bm.verts])\n",
    "\n",
    "        n = np.array([v.normal for v in self.verts])\n",
    "        u = eij - np.sum(eij*n, axis=1)[:,None]\n",
    "        u = u/np.linalg.norm(u, axis=1)[:,None]\n",
    "        v = np.cross(n, u)\n",
    "        v = v/np.linalg.norm(v, axis=1)[:,None]\n",
    "\n",
    "        self.vertex_attributes[\"u\"] = u\n",
    "        self.vertex_attributes[\"v\"] = v\n",
    "\n",
    "    def _custom_solve_Ab_vectorized(self, a, b, c, d, e, f, vec_b):\n",
    "        \"\"\"\n",
    "        Heavily optimised method to solve for Ax = vec_b (least square) (about 45x faster than scipy.sparse.linalg.lsqr(A, vec_b)). A is of the form:\n",
    "        A = [\n",
    "        A_block_0, 0, 0, ...\n",
    "        0, A_block_1, 0, ...\n",
    "        0, 0, A_block_2, ...\n",
    "        ]\n",
    "        with\n",
    "        A_block_i = [\n",
    "        [a[i], b[i], 0],\n",
    "        [0, a[i], b[i]],\n",
    "        [c[i], d[i], 0],\n",
    "        [0, c[i], d[i]],\n",
    "        [e[i], f[i], 0],\n",
    "        [0, e[i], f[i]]\n",
    "        ]\n",
    "        One knows that min||Ax-vec_b||^2 is obtained for x = ((A.T @ A)^{-1}) @ A.T @ vec_b.\n",
    "        Let's first compute (A.T @ A)^{-1} (AtAinv in the code)\n",
    "        then A.T @ vec_b (Atvec_b in the code)\n",
    "        before returning x\n",
    "        \"\"\"\n",
    "        aa, bb, cc, dd, ee, ff = a*a, b*b, c*c, d*d, e*e, f*f\n",
    "        aaa, bbb, ccc, ddd, eee, fff = aa*a, bb*b, cc*c, dd*d, ee*e, ff*f\n",
    "        aaaa, bbbb, cccc, dddd, eeee, ffff = aaa*a, bbb*b, ccc*c, ddd*d, eee*e, fff*f\n",
    "\n",
    "        denom = aaaa*dd + aaaa*ff - 2*aaa*b*c*d - 2*aaa*b*e*f + aa*bb*cc + aa*bb*dd + aa*bb*ee + aa*bb*ff + aa*cc*dd + 2*aa*cc*ff - 2*aa*c*d*e*f + aa*dddd + 2*aa*dd*ee + 2*aa*dd*ff + aa*ee*ff + aa*ffff - 2*a*bbb*c*d - 2*a*bbb*e*f - 2*a*b*ccc*d - 2*a*b*cc*e*f - 2*a*b*c*ddd - 2*a*b*c*d*ee - 2*a*b*c*d*ff - 2*a*b*dd*e*f - 2*a*b*eee*f - 2*a*b*e*fff + bbbb*cc + bbbb*ee + bb*cccc + bb*cc*dd + 2*bb*cc*ee + 2*bb*cc*ff - 2*bb*c*d*e*f + 2*bb*dd*ee + bb*eeee + bb*ee*ff + cccc*ff - 2*ccc*d*e*f + cc*dd*ee + cc*dd*ff + cc*ee*ff + cc*ffff - 2*c*ddd*e*f - 2*c*d*eee*f - 2*c*d*e*fff + dddd*ee + dd*eeee + dd*ee*ff\n",
    "        m00 = aa*dd + aa*ff - 2*a*b*c*d - 2*a*b*e*f + bbbb + bb*cc + 2*bb*dd + bb*ee + 2*bb*ff + cc*ff - 2*c*d*e*f + dddd + dd*ee + 2*dd*ff + ffff\n",
    "        m01 = -a*bbb - a*b*dd - a*b*ff - bb*c*d - bb*e*f - c*ddd - c*d*ff - dd*e*f - e*fff\n",
    "        m02 = aa*bb + 2*a*b*c*d + 2*a*b*e*f + cc*dd + 2*c*d*e*f + ee*ff\n",
    "        # m10 = m01\n",
    "        m11 = aa*bb + aa*dd + aa*ff + bb*cc + bb*ee + cc*dd + cc*ff + dd*ee + ee*ff\n",
    "        m12 = -aaa*b - aa*c*d - aa*e*f - a*b*cc - a*b*ee - ccc*d - cc*e*f - c*d*ee - eee*f\n",
    "        # m20 = m02\n",
    "        # m21 = m12\n",
    "        m22 = aaaa + 2*aa*cc + aa*dd + 2*aa*ee + aa*ff - 2*a*b*c*d - 2*a*b*e*f + bb*cc + bb*ee + cccc + 2*cc*ee + cc*ff - 2*c*d*e*f + dd*ee + eeee\n",
    "\n",
    "        nvertex = denom.shape[0]\n",
    "        denom_inv = 1./denom\n",
    "        m00, m01, m02, m11, m12, m22 = m00*denom_inv, m01*denom_inv, m02*denom_inv, m11*denom_inv, m12*denom_inv, m22*denom_inv\n",
    "        val = np.zeros(9*nvertex)\n",
    "        val[0::9] = m00\n",
    "        val[1::9] = m01\n",
    "        val[2::9] = m02\n",
    "        val[3::9] = m01\n",
    "        val[4::9] = m11\n",
    "        val[5::9] = m12\n",
    "        val[6::9] = m02\n",
    "        val[7::9] = m12\n",
    "        val[8::9] = m22\n",
    "        row = np.repeat(np.arange(3*nvertex), 3)\n",
    "        col = np.array([0,1,2]*(3*nvertex)) + 3*np.repeat(np.arange(nvertex), 9)\n",
    "\n",
    "        AtAinv = scipy.sparse.coo_array((val, (row, col))).tocsr()\n",
    "  \n",
    "        Atvec_b = np.zeros(3*nvertex)\n",
    "        Atvec_b[0::3] = a * vec_b[0::6] + c * vec_b[2::6] + e * vec_b[4::6]\n",
    "        Atvec_b[1::3] = b * vec_b[0::6] + a * vec_b[1::6] + d * vec_b[2::6] + c * vec_b[3::6] + f * vec_b[4::6] + e * vec_b[5::6]\n",
    "        Atvec_b[2::3] = b * vec_b[1::6] + d * vec_b[3::6] + f * vec_b[5::6]\n",
    "\n",
    "        x = AtAinv.dot(Atvec_b) # Ax = vec_b least square : min||Ax - vec_b||^2 ==> x = (A.T * A)^{-1} * A.T * vec_b\n",
    "\n",
    "        return x\n",
    "\n",
    "    def calculate_curvature_vectorized(self, use_optimized_solve=True):\n",
    "\n",
    "        nface = len(self.faces)\n",
    "        nvertex = len(self.verts)\n",
    "\n",
    "        # co = np.array([v.co for v in self.verts])\n",
    "        nv = np.array([v.normal for v in self.verts])\n",
    "        nf = np.array([f.normal for f in self.faces])\n",
    "        # fv = np.array([[v.index for v in f.verts] for f in self.faces])\n",
    "\n",
    "        uf = self.co[self.fv[:,0]]-self.co[self.fv[:,1]]\n",
    "        uf = uf/np.linalg.norm(uf, axis=1)[:,None]\n",
    "        vf = np.cross(nf, uf)\n",
    "\n",
    "        vi, vj, vk = self.co[self.fv[:,0]], self.co[self.fv[:,1]], self.co[self.fv[:,2]]\n",
    "        ni, nj, nk = nv[self.fv[:,0]], nv[self.fv[:,1]], nv[self.fv[:,2]]\n",
    "        \n",
    "        ejk, eki, eij = vk-vj, vi-vk, vj-vi\n",
    "        njk, nki, nij = nk-nj, ni-nk, nj-ni\n",
    "\n",
    "        a, b = np.einsum('ij,ij->i', ejk, uf), np.einsum('ij,ij->i', ejk, vf)\n",
    "        c, d = np.einsum('ij,ij->i', eki, uf), np.einsum('ij,ij->i', eki, vf)\n",
    "        e, f = np.einsum('ij,ij->i', eij, uf), np.einsum('ij,ij->i', eij, vf)\n",
    "\n",
    "        vec_b = np.zeros(6*nface)\n",
    "        vec_b[0::6] = np.einsum('ij,ij->i', njk, uf)\n",
    "        vec_b[1::6] = np.einsum('ij,ij->i', njk, vf)\n",
    "        vec_b[2::6] = np.einsum('ij,ij->i', nki, uf)\n",
    "        vec_b[3::6] = np.einsum('ij,ij->i', nki, vf)\n",
    "        vec_b[4::6] = np.einsum('ij,ij->i', nij, uf)\n",
    "        vec_b[5::6] = np.einsum('ij,ij->i', nij, vf)\n",
    "\n",
    "        if not use_optimized_solve:\n",
    "            value = np.vstack((a,b, a,b, c,d, c,d, e,f, e,f)).T\n",
    "            row = np.repeat(np.arange(6*nface),2)\n",
    "            col = np.tile([0, 1, 1, 2], 3*len(bm.faces)).reshape((-1,4)) + 3*np.repeat(np.arange(len(bm.faces)), 3).reshape((-1,1))\n",
    "            value = value.ravel()\n",
    "            col = col.ravel()\n",
    "            A = scipy.sparse.coo_array((value, (row, col))).tocsr()\n",
    "            x = scipy.sparse.linalg.lsqr(A, vec_b)[0] # only return the solution\n",
    "        else:\n",
    "            x = self._custom_solve_Ab_vectorized(a, b, c, d, e, f, vec_b) # Heavily optimized code to speed up the computation : about 45x faster than scipy.sparse.linalg.lsqr(A, vec_b)\n",
    "        # project X into the vertex frame\n",
    "        weights = self.facecorner_attributes[\"area\"] / self.vertex_attributes[\"area\"][self.fv.ravel()]\n",
    "        fv_ravel = self.fv.ravel()\n",
    "        uv = self.vertex_attributes[\"u\"]\n",
    "        vv = self.vertex_attributes[\"v\"]\n",
    "        uv_dup = uv[fv_ravel]\n",
    "        vv_dup = vv[fv_ravel]\n",
    "\n",
    "        nv_dup = nv[fv_ravel].reshape((3*self.fv.shape[0], 3))\n",
    "        nf_dup = np.tile(nf,3).reshape((3*nface, 3))\n",
    "        uf_dup = np.tile(uf,3).reshape((3*nface, 3))\n",
    "        vf_dup = np.tile(vf,3).reshape((3*nface, 3))\n",
    "        x_dup = np.tile(x.reshape((nface, 3)), 3).reshape((3*nface, 3))\n",
    "        new_ku, new_kuv, new_kv = project_curvature_tensor_vectorized(uf_dup, vf_dup, nf_dup, x_dup[:,0], x_dup[:,1], x_dup[:,2], uv_dup, vv_dup, nv_dup)\n",
    "        # new_k is on the facecorner domain. weight it to express it on the vertex domain\n",
    "        # Build a matrix of mass so that M * new_k is on the vertex domain\n",
    "        row, col, val = [], [], []\n",
    "        for v in self.verts:\n",
    "            for fc in self.vert2facecorner[v]:\n",
    "                row.append(v.index)\n",
    "                col.append(fc.index)\n",
    "                val.append(weights[fc.index])\n",
    "\n",
    "        M = scipy.sparse.coo_array((val, (row, col))).tocsr()\n",
    "        ku = M.dot(new_ku)\n",
    "        kuv = M.dot(new_kuv)\n",
    "        kv = M.dot(new_kv)\n",
    "        # sfm = np.vstack((ku, kuv, kv)).T # curvature matrix is [[ku, kuv], [kuv, kv]] for each [ku, kuv, kv] in sfm\n",
    "\n",
    "        c, s, tt = np.ones(nvertex), np.zeros(nvertex), np.zeros(nvertex) \n",
    "        h = 0.5 * (kv-ku)/kuv\n",
    "        root = np.sqrt(1 + h*h)\n",
    "        hneg = h<0\n",
    "        hpos = ~hneg\n",
    "        tt[hneg] = 1/(h[hneg]-root[hneg])\n",
    "        tt[hpos] = 1/(h[hpos]+root[hpos])\n",
    "        c = 1 / np.sqrt(1 + tt * tt)\n",
    "        s = tt * c\n",
    "        ttkuv = tt * kuv\n",
    "        k1 = ku - ttkuv\n",
    "        k2 = kv + ttkuv\n",
    "        kuv0 = kuv == 0\n",
    "        k1[kuv0] = ku[kuv0]\n",
    "        k2[kuv0] = kv[kuv0]\n",
    "        k1lk2 = np.abs(k1) < np.abs(k2)\n",
    "        # abs(k1) > abs(k2) ==> e1 = cos * uv - sin * vv\n",
    "        # else ==> e1 = sin * uv + cos * vp\n",
    "        c, s = c[:,None], s[:,None]\n",
    "        e1 = c * uv - s * vv\n",
    "        e1[k1lk2] = s[k1lk2]*uv[k1lk2] + c[k1lk2] * vv[k1lk2]\n",
    "        e2 = np.cross(nv, e1)\n",
    "        e2 = e2 / np.linalg.norm(e2, axis=1)[:,None]\n",
    "        return k1, k2, e1, e2\n",
    "\n",
    "    def assign_distinguished_vector_X(self):\n",
    "        all_X = []\n",
    "        for v in self.verts:\n",
    "            if v.is_boundary:\n",
    "                boundary_edges = [e for e in v.link_edges if e.is_boundary]\n",
    "                if len(boundary_edges) != 2:\n",
    "                    raise ValueError(f\"Non manifold mesh : vertex {v.index} does not have exactly 2 adjacent boundary edges\")\n",
    "                other_vs = [boundary_edges[0].other_vert(v), boundary_edges[1].other_vert(v)]\n",
    "                # select the hedge starting at v and having a non None face\n",
    "                vector_X = None\n",
    "                for ov in other_vs:\n",
    "                    key = (v.index, ov.index)\n",
    "                    key_r = (ov.index, v.index)\n",
    "                    for k in [key, key_r]:\n",
    "                        he = self.dict_vert2heedges[k]\n",
    "                        if he.vertex == v and he.face is not None:\n",
    "                            vector_X = he\n",
    "                            break\n",
    "                    if vector_X is not None:\n",
    "                        break\n",
    "                if vector_X is None:\n",
    "                    raise ValueError(f\"Unable to find an X for boundary vertex {v.index}\")\n",
    "                all_X.append(vector_X)\n",
    "                # if (v.index, boundary_edges[0].other_vert(v).index) in self.dict_vert2heedges:\n",
    "                #     all_X.append(self.dict_vert2heedges[(v.index, boundary_edges[0].other_vert(v).index)])\n",
    "                # elif (v.index, boundary_edges[1].other_vert(v).index) in self.dict_vert2heedges:\n",
    "                #     all_X.append(self.dict_vert2heedges[(v.index, boundary_edges[1].other_vert(v).index)])\n",
    "                # else:\n",
    "                #     raise ValueError(f\"Unable to find an X for boundary vertex {v.index}\")\n",
    "            else:\n",
    "                all_X.append(self.dict_vert2heedges[(v.index, v.link_edges[0].other_vert(v).index)])\n",
    "        # all_X = np.array(all_X)\n",
    "        self.vertex_attributes[\"X\"] = all_X \n",
    "\n",
    "    def calculate_angle_sum(self):\n",
    "        if self.internal_angles is None:\n",
    "            self._calculate_corner_angles_and_face_areas()\n",
    "        angle_sum = np.zeros(len(self.verts))\n",
    "        for i, v in enumerate(self.verts):\n",
    "            s = 0\n",
    "            for fc in self.vert2facecorner[v]:\n",
    "                s += self.internal_angles[fc.index]\n",
    "            angle_sum[i] = s\n",
    "\n",
    "        self.vertex_attributes[\"angle_sum\"] = angle_sum\n",
    "\n",
    "    def calculate_angle_defect(self):\n",
    "        if not \"angle_sum\" in self.vertex_attributes:\n",
    "            self.calculate_angle_sum()\n",
    "\n",
    "        boundary_coeff =  2 - np.array([v.is_boundary for v in self.verts]) # v on interior : 2 ; v on boundary : 1\n",
    "        self.vertex_attributes[\"angle_defect\"] = np.pi * boundary_coeff - self.vertex_attributes[\"angle_sum\"]\n",
    "\n",
    "    def calculate_gaussian_curvature(self):\n",
    "        if not \"area\" in self.vertex_attributes:\n",
    "            self._calculate_vertex_area()\n",
    "        if not \"angle_defect\" in self.vertex_attributes:\n",
    "            self.calculate_angle_defect()\n",
    "\n",
    "        self.vertex_attributes[\"gaussian_curvature\"] = self.vertex_attributes[\"angle_defect\"] / self.vertex_attributes[\"area\"]\n",
    "\n",
    "    def calculate_rescaled_factor(self):\n",
    "        if \"angle_sum\" not in self.vertex_attributes:\n",
    "            self.calculate_angle_sum()\n",
    "        self.vertex_attributes[\"s\"] = 2 * np.pi / self.vertex_attributes[\"angle_sum\"]\n",
    "        boundary_bool = np.array([v.is_boundary for v in self.verts])\n",
    "        self.vertex_attributes[\"s\"][boundary_bool] = 1\n",
    "\n",
    "    def calculate_rescaled_angle_from_X(self):\n",
    "        for i, v in enumerate(self.verts):\n",
    "            heX = self.vertex_attributes[\"X\"][i]\n",
    "            he_current = heX\n",
    "            scale_factor = self.vertex_attributes[\"s\"][v.index]\n",
    "            counter = 0\n",
    "            summed_angle = 0.0\n",
    "            n_adj_faces = len(v.link_faces)\n",
    "            # print(\"//////////////////////\")\n",
    "            # print(v)\n",
    "            # print(self.vertex_attributes[\"X\"][v.index])\n",
    "            # while he_current.next.next.twin != heX:\n",
    "            while he_current != heX or counter == 0:\n",
    "                if counter == n_adj_faces + 1:\n",
    "                    raise ValueError(\"Infinite loop detected\")\n",
    "                counter+=1\n",
    "\n",
    "                he_current.angle_from_X = summed_angle * scale_factor\n",
    "                facecorner = self.face_vertex_to_facecorner[he_current.face][v]\n",
    "                summed_angle += self.internal_angles[facecorner.index]\n",
    "                # print(he_current)\n",
    "                # print(he_current.face)\n",
    "                # print(he_current.angle_from_X)\n",
    "                # print(summed_angle)\n",
    "                # print(he_current.next.next.twin)\n",
    "                # print()\n",
    "                he_current = he_current.next.next.twin\n",
    "                if he_current.face is None:\n",
    "                    he_current.angle_from_X = summed_angle * scale_factor\n",
    "\n",
    "                    # print(f\"breaking at v={v.index}\")\n",
    "                    break\n",
    "                # if he_current is None:\n",
    "                #     raise NotImplementedError(\"Do something\")\n",
    "                \n",
    "    def calculate_transform_coefficient(self):\n",
    "        # compute the r_ij coeff\n",
    "        for k in self.dict_vert2heedges:\n",
    "            he_ij = self.dict_vert2heedges[k]\n",
    "            he_ji = he_ij.twin\n",
    "            theta_i = he_ij.angle_from_X\n",
    "            # why -pi below : assume that he_ij is the distinguished vector X of vertex vi (he_ij == vi.X) and similary he_ji==vj.X\n",
    "            # Then the angles theta_i and theta_j are both 0, yet vi.X = -vj.X\n",
    "            # So subtract pi to calculate the angle theta_j to he_ij from vj's perspective (instead of he_ji from vj's perspective)\n",
    "            theta_j = he_ji.angle_from_X - np.pi \n",
    "            rho_ij = theta_j - theta_i\n",
    "            he_ij.transport_coeff = rho_ij\n",
    "\n",
    "\n",
    "    def calculate_q_coefficient(self):\n",
    "        qs = np.zeros(len(self.verts), dtype=complex)\n",
    "        for e in self.edges:\n",
    "            vi, vj = e.verts\n",
    "            vi, vj = e.verts\n",
    "            he = self.dict_vert2heedges[(vi.index, vj.index)]\n",
    "\n",
    "            angle_j = he.twin.angle_from_X - np.pi\n",
    "            angle_i = he.angle_from_X\n",
    "\n",
    "            vi_angle, vj_angle = self.vertex_attributes[\"constrained_angles\"][vi.index], self.vertex_attributes[\"constrained_angles\"][vj.index]\n",
    "            if not np.isnan(vj_angle):\n",
    "                qs[vj.index] += (np.cos(2*angle_j) + 1j * np.sin(2*angle_j)) * vj_angle\n",
    "            if not np.isnan(vi_angle):\n",
    "                qs[vi.index] += (np.cos(2*angle_i) + 1j * np.sin(2*angle_i)) * vi_angle\n",
    "\n",
    "        self.vertex_attributes[\"q\"] = qs\n",
    "\n",
    "\n",
    "    def calculate_q_coefficientPAPER(self):\n",
    "\n",
    "        def get_dihedral_angle(fA, fB):\n",
    "            xprod = np.cross(fA.normal, fB.normal)\n",
    "            N = xprod/np.linalg.norm(xprod)\n",
    "            return np.arctan2(np.dot(N, xprod), np.dot(fA.normal, fB.normal))\n",
    "\n",
    "        qs = np.zeros(len(self.verts), dtype=complex)\n",
    "        for e in self.edges:\n",
    "            if e.is_boundary:\n",
    "                continue\n",
    "\n",
    "            vi, vj = e.verts\n",
    "            he = self.dict_vert2heedges[(vi.index, vj.index)]\n",
    "            dih_angle = get_dihedral_angle(he.face, he.twin.face)\n",
    "            len_edge = np.linalg.norm(vj.co - vi.co)\n",
    "            q_edge = - complex(0.5*dih_angle*len_edge, 0)\n",
    "\n",
    "            angle_j = he.twin.angle_from_X - np.pi\n",
    "            angle_i = he.angle_from_X\n",
    "\n",
    "            qs[vj.index] += (np.cos(2*angle_j) + 1j * np.sin(2*angle_j)) * q_edge\n",
    "            qs[vi.index] += (np.cos(2*angle_i) + 1j * np.sin(2*angle_i)) * q_edge\n",
    "\n",
    "        self.vertex_attributes[\"q\"] = qs\n",
    "\n",
    "    def calculate_holonomy(self):\n",
    "        holonomy = []\n",
    "        for f in self.faces:\n",
    "            vi, vj, vk = f.verts # ccw order\n",
    "            ii, ij, ik = vi.index, vj.index, vk.index\n",
    "            # heij, hejk, heki = self.dict_vert2heedges[(ii, ij)], self.dict_vert2heedges[(ij, ik)], self.dict_vert2heedges[(ik, ii)]\n",
    "            alpha_i = self.internal_angles[self.face_vertex_to_facecorner[f][vi].index]\n",
    "            alpha_j = self.internal_angles[self.face_vertex_to_facecorner[f][vj].index]\n",
    "            alpha_k = self.internal_angles[self.face_vertex_to_facecorner[f][vk].index]\n",
    "            si, sj, sk = self.vertex_attributes[\"s\"][ii], self.vertex_attributes[\"s\"][ij], self.vertex_attributes[\"s\"][ik]\n",
    "            omega_ijk = alpha_i *(si-1) + alpha_j * (sj-1) + alpha_k * (sk-1) # identical to he_ij.r + he_jk.r + he_ki.r (up to 2pi) with r = transport_coeff\n",
    "            holonomy.append(omega_ijk)\n",
    "        self.face_attributes[\"holonomy\"] = np.array(holonomy)\n",
    "    \n",
    "    def compute_face_frame(self):\n",
    "\n",
    "        vi, vj, vk = self.co[self.fv[:,0]], self.co[self.fv[:,1]], self.co[self.fv[:,2]]\n",
    "        e1 = vj - vi\n",
    "        e1 = e1 / np.linalg.norm(e1, axis=1)[:,None]\n",
    "        e2 = vk - vi\n",
    "        e2 = e2 - e1 * np.einsum('ij,ij->i',e1, e2)[:,None]\n",
    "        e2 = e2/np.linalg.norm(e2, axis=1)[:,None]\n",
    "\n",
    "        self.face_attributes[\"e1\"] = e1\n",
    "        self.face_attributes[\"e2\"] = e2\n",
    "\n",
    "obj = bpy.data.objects[\"Sphere\"]\n",
    "obj = bpy.data.objects[\"Suzanne\"]\n",
    "obj = bpy.data.objects[\"Torus.001\"]\n",
    "\n",
    "bpy.ops.object.mode_set(mode='OBJECT')\n",
    "mesh = obj.data\n",
    "bm = MYMesh()\n",
    "bm.from_mesh(mesh)\n",
    "bm.ensure_lookup_tables()\n",
    "bm.create_halfedge_datastructure()\n",
    "bm.calculate_angle_sum()\n",
    "bm.calculate_rescaled_factor()\n",
    "bm.assign_distinguished_vector_X()\n",
    "bm.calculate_rescaled_angle_from_X()\n",
    "bm.calculate_transform_coefficient()\n",
    "bm.calculate_holonomy()\n",
    "bm.compute_face_frame()\n",
    "# bm.calculate_q_coefficient()\n",
    "\n",
    "print(f\"|V|:{len(bm.verts)}, |E|:{len(bm.edges)}, |F|:{len(bm.faces)}\")\n",
    "\n",
    "# Load curves from the \"GuideCurves\" collection\n",
    "guide_curves = load_guide_curves(\"GuideCurves\")\n",
    "polylines, tangents, face_indices = [], [], []\n",
    "\n",
    "# Discretize each curve into polylines\n",
    "for index_polyline, curve in enumerate(guide_curves):\n",
    "    sampling_step = 0.05  # Adjust the sampling step as needed\n",
    "    polyline = curve_2_polyline(curve, sampling_step)\n",
    "    for obj in bpy.data.objects:\n",
    "        if obj.name.startswith(\"polyline_\"):\n",
    "            bpy.data.objects.remove(obj, do_unlink=True)\n",
    "\n",
    "    # polyline = [p[0] for p in polyline]\n",
    "    polyline, face_idx = project_polyline_to_mesh(polyline, bm.bm)\n",
    "    polyline, face_idx = resample_polyline_1_point_per_face(polyline, face_idx)\n",
    "    tangent = get_tangent(polyline)\n",
    "    polyline_to_mesh(polyline, tangent, name=f\"polyline_{index_polyline}\")\n",
    "    polylines.append(polyline)\n",
    "    tangents.append(tangent)\n",
    "    face_indices.append(face_idx)\n",
    "\n",
    "\n",
    "face_indices = [y for x in face_indices for y in x]\n",
    "tangents = [y for x in tangents for y in x]\n",
    "\n",
    "print(f\"{len(polylines)} curves loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def rotate_axis_angle_single_vector(vector, axis, angle):\n",
    "    c = np.cos(angle)\n",
    "    s = np.sin(angle)\n",
    "    axis = axis/np.linalg.norm(axis)\n",
    "    dot = np.dot(axis, vector)\n",
    "    xprod = np.cross(axis, vector)\n",
    "    return (1-c) * dot * axis + c * vector + s * xprod\n",
    "\n",
    "\n",
    "def calculate_constrained_angle(self:MYMesh, face_indices, vectors):\n",
    "    \"\"\"\n",
    "    Calculate the constrained angle of each face in face_indices, such that the constrained direction is given by vectors:\n",
    "    Args:\n",
    "        face_indices List[int] : indices of the face being constrained\n",
    "        vectors List[Vector] : direction in which the field must be constrained\n",
    "    \"\"\"\n",
    "    self.face_attributes[\"constrained_angles\"] = np.nan * np.ones(len(self.faces))\n",
    "    self.vertex_attributes[\"constrained_angles\"] = np.nan * np.ones(len(self.verts))\n",
    "    e1 = self.face_attributes[\"e1\"]\n",
    "    for i, idx in enumerate(face_indices):\n",
    "        vec = np.array(vectors[i].normalized())\n",
    "        face = self.faces[idx]\n",
    "        normal = face.normal\n",
    "        ei1 = e1[idx]\n",
    "        xprod = np.cross(ei1, vec)\n",
    "        angle = np.arctan2(np.dot(xprod, normal), np.dot(ei1, vec))\n",
    "        self.face_attributes[\"constrained_angles\"][idx] = angle\n",
    "        for v in face.verts:\n",
    "            normal = np.array(v.normal)\n",
    "            X = bm.vertex_attributes[\"X\"][v.index]\n",
    "            X = np.array(X.verts[1].co - X.verts[0].co)\n",
    "            ei1 = X / np.linalg.norm(X)\n",
    "            xprod = np.cross(ei1, vec)\n",
    "            angle = np.arctan2(np.dot(xprod, normal), np.dot(ei1, vec))\n",
    "            self.vertex_attributes[\"constrained_angles\"][v.index] = angle\n",
    "\n",
    "calculate_constrained_angle(bm, face_indices, tangents)\n",
    "bm.calculate_q_coefficient()\n",
    "\n",
    "bm.vertex_attributes[\"constrained_angles\"]\n",
    "# attributes_to_delete = []\n",
    "# for attr in mesh.attributes:\n",
    "#     delete_attr = False\n",
    "#     for s in [\"angle\", \"u_aligned\", \"X\", \"vf\", \"vector\", \"constrained\", \"e1\", \"field\"]:\n",
    "#         if s in attr.name:\n",
    "#             delete_attr = True\n",
    "#             break\n",
    "#     if delete_attr:\n",
    "#         attributes_to_delete.append(attr)\n",
    "            \n",
    "# for attr in attributes_to_delete:\n",
    "#     try:\n",
    "#         mesh.attributes.remove(attr)\n",
    "#     except RuntimeError:\n",
    "#         pass\n",
    "\n",
    "# vector_field = np.zeros((len(bm.verts), 3))\n",
    "# for v in bm.verts:\n",
    "#     if not np.isnan(bm.vertex_attributes[\"constrained_angles\"][v.index]):\n",
    "#         X = bm.vertex_attributes[\"X\"][v.index]\n",
    "#         X = np.array(X.verts[1].co - X.verts[0].co)\n",
    "#         ei1 = X / np.linalg.norm(X)\n",
    "#         vector_field[v.index] = rotate_axis_angle_single_vector(ei1, v.normal, bm.vertex_attributes[\"constrained_angles\"][v.index])\n",
    "\n",
    "\n",
    "# attr = mesh.attributes.new(name=\"vector_field\", type='FLOAT_VECTOR', domain='POINT')\n",
    "# attr.data.foreach_set('vector', vector_field.flatten())\n",
    "# vector_field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BMesh' object has no attribute 'v'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv\u001b[49m\n",
      "Cell \u001b[1;32mIn[107], line 114\u001b[0m, in \u001b[0;36mMYMesh.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# Delegate attribute access to the internal bmesh instance\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm, item)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BMesh' object has no attribute 'v'"
     ]
    }
   ],
   "source": [
    "bm.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def smallest_eigenvector_square(energy_matrix, mass_matrix, n_iterations, u=None):\n",
    "    \"\"\"\n",
    "    Compute the smallest eigenvector of the square using an iterative method.\n",
    "\n",
    "    Parameters:\n",
    "    - energy_matrix: Sparse energy matrix (scipy.sparse.csr_matrix)\n",
    "    - mass_matrix: Sparse mass matrix (scipy.sparse.csr_matrix)\n",
    "    - n_iterations: Number of iterations for the method.\n",
    "\n",
    "    Returns:\n",
    "    - x: Approximation of the smallest eigenvector.\n",
    "    \"\"\"\n",
    "    N = energy_matrix.shape[0]  # Number of rows\n",
    "    if u is None:\n",
    "        u = np.random.rand(N)       # Random initial vector\n",
    "    x = u.copy()                # Initialize x\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Solve the linear system: energy_matrix * x = mass_matrix * u\n",
    "        x = spsolve(energy_matrix, mass_matrix @ u)\n",
    "\n",
    "        # Re-normalize x with respect to the mass matrix\n",
    "        x = normalize(x, mass_matrix)\n",
    "        # x = x/np.absolute(x)\n",
    "\n",
    "        # Update u for the next iteration\n",
    "        u = x.copy()\n",
    "\n",
    "    return x\n",
    "\n",
    "def normalize(x, mass_matrix):\n",
    "    \"\"\"\n",
    "    Normalize vector x with respect to the mass matrix.\n",
    "    \"\"\"\n",
    "    norm = np.sqrt(x @ (mass_matrix @ x))  # Quadratic form norm\n",
    "    return x / norm if norm != 0 else x\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import splu\n",
    "from scipy.sparse.linalg import LinearOperator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc(self:MYMesh, n, s, lambda_t=0):\n",
    "\n",
    "    secint = SectionIntegrals()\n",
    "    row_m, col_m, val_m = [], [], [] # coo for mass\n",
    "    row_e, col_e, val_e = [], [], [] # and energy\n",
    "    constraint_row, constraint_col, constraint_val = [], [], []  # COO for constraints\n",
    "\n",
    "    for face_index, f in enumerate(self.faces):\n",
    "        vi, vj, vk = f.verts\n",
    "        vertex_indices = [vi.index, vj.index, vk.index]\n",
    "        he = [self.dict_vert2heedges[(vi.index, vj.index)], self.dict_vert2heedges[(vj.index, vk.index)], self.dict_vert2heedges[(vk.index, vi.index)]]\n",
    "\n",
    "        eij, ejk, eki = vj.co-vi.co, vk.co-vj.co, vi.co-vk.co\n",
    "        lij2 = eij[0]*eij[0] + eij[1]*eij[1] + eij[2]*eij[2]\n",
    "        ljk2 = ejk[0]*ejk[0] + ejk[1]*ejk[1] + ejk[2]*ejk[2]\n",
    "        lki2 = eki[0]*eki[0] + eki[1]*eki[1] + eki[2]*eki[2]\n",
    "        pn2 = [lij2, ljk2, lki2]\n",
    "        # p = [eij, ejk, eki]\n",
    "        dot_products = [np.dot(eij, ejk), np.dot(ejk, eki), np.dot(eki, eij)]\n",
    "\n",
    "        rc = n * np.array([he[0].transport_coeff, he[1].transport_coeff, he[2].transport_coeff]) # MULTIPLIED BY N\n",
    "        rc = np.conjugate(np.cos(rc) + 1j * np.sin(rc))\n",
    "\n",
    "        A = self.face_areas[face_index]\n",
    "        om = n * self.face_attributes[\"holonomy\"][face_index] # MULTIPLIED BY N\n",
    "        i,j,k = vertex_indices\n",
    "\n",
    "        Mii = A * secint.mass_ii() # same as Mjj, Mkk\n",
    "        row_m.extend([i,   j,   k])\n",
    "        col_m.extend([i,   j,   k])\n",
    "        val_m.extend([Mii, Mii, Mii])\n",
    "\n",
    "        Mij = A * secint.mass_ij(om)\n",
    "        row_m.extend([i,   j,   k])\n",
    "        col_m.extend([j,   k,   i])\n",
    "        val_m.extend(rc * Mij)\n",
    "\n",
    "        row_m.extend([j,   k,   i])\n",
    "        col_m.extend([i,   j,   k])\n",
    "        val_m.extend(np.conj(rc * Mij))\n",
    "\n",
    "        snKii = (s*(om/A))*Mii\n",
    "        Aii = secint.dirichlet_ii(om, pn2[0], -dot_products[2], pn2[2]) / A - snKii\n",
    "        Ajj = secint.dirichlet_ii(om, pn2[1], -dot_products[0], pn2[0]) / A - snKii\n",
    "        Akk = secint.dirichlet_ii(om, pn2[2], -dot_products[1], pn2[1]) / A - snKii\n",
    "        row_e.extend([i,   j,   k])\n",
    "        col_e.extend([i,   j,   k])\n",
    "        val_e.extend([Aii, Ajj, Akk])\n",
    "\n",
    "\n",
    "        snKij = s*((om/A)*Mij-complex(0,.5))\n",
    "        Aij = (secint.dirichlet_ij(om, pn2[2], -dot_products[1], pn2[1]) / A - snKij) * rc[0]\n",
    "        Ajk = (secint.dirichlet_ij(om, pn2[0], -dot_products[2], pn2[2]) / A - snKij) * rc[1]\n",
    "        Aki = (secint.dirichlet_ij(om, pn2[1], -dot_products[0], pn2[0]) / A - snKij) * rc[2]\n",
    "        row_e.extend([i,        j,       j,        k,       k,        i])\n",
    "        col_e.extend([j,        i,       k,        j,       i,        k])\n",
    "        val_e.extend([Aij, np.conj(Aij), Ajk, np.conj(Ajk), Aki, np.conj(Aki)])\n",
    "\n",
    "   \n",
    "\n",
    "    mass_matrix = scipy.sparse.coo_array((val_m, (row_m, col_m))).tocsr()\n",
    "    # mass_matrix = 0.5 * (mass_matrix.T + mass_matrix)\n",
    "    energy_matrix = scipy.sparse.coo_array((val_e, (row_e, col_e))).tocsr()\n",
    "    energy_matrix = energy_matrix + (-lambda_t + 1e-9) * mass_matrix\n",
    "    print(mass_matrix.shape, energy_matrix.shape)\n",
    "\n",
    "    \n",
    "\n",
    "    return mass_matrix, energy_matrix\n",
    "\n",
    "def smallest_eigenvector_square_prefactored(energy_matrix, mass_matrix, n_iterations, u=None, q=None):\n",
    "    # Step 1: Cholesky factorization (A = L * L^T)\n",
    "    prefactorized_solver = splu(energy_matrix.tocsc())  # LU decomposition (includes Cholesky for symmetric positive-definite)\n",
    "    \n",
    "    # Get size of the matrix\n",
    "    N = energy_matrix.shape[0]\n",
    "\n",
    "    # Initialize vectors\n",
    "    if u is None:\n",
    "        u = np.random.rand(N) + 1j*np.random.rand(N)\n",
    "\n",
    "    if q is None:\n",
    "        q = np.zeros(N) + 1j*np.zeros(N)\n",
    "\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        # Step 2: Solve A * x = M * u using prefactorized A\n",
    "        b = mass_matrix @ (u + q)  # Compute M * u\n",
    "        x = prefactorized_solver.solve(b)  # Solve A * x = b (using prefactorized L and L^T)\n",
    "        \n",
    "        # Step 3: Normalize x with respect to mass_matrix\n",
    "        scale = np.sqrt(u @ (mass_matrix @ u))  # norm(x, mass_matrix)\n",
    "        u /= scale  # Normalize\n",
    "\n",
    "        # Step 4: Update u\n",
    "        # u = x.copy()\n",
    "    \n",
    "    return x\n",
    "\n",
    "def smoothest_curvature_aligned(self:MYMesh, mass_matrix, energy_matrix, n):\n",
    "    # if n not in [2, 4]:\n",
    "    #     raise ValueError(f\"n must be either 2 or 4. Got n = {n}\")\n",
    "    \n",
    "    q = self.vertex_attributes[\"q\"]\n",
    "    print(q)\n",
    "    if n == 4:\n",
    "        q = q*q\n",
    "    u = mass_matrix @ q\n",
    "    normQ = np.abs(np.real(np.sum(np.conj(q) * u)))\n",
    "    q = u/np.sqrt(normQ)\n",
    "    u = spsolve(energy_matrix, q)\n",
    "\n",
    "    q = mass_matrix @ u\n",
    "    normU = np.real(np.sum(np.conj(u) * q))\n",
    "\n",
    "    print(f\"Corresponding t value : {1/(1+np.sqrt(np.abs(normU)))}\")\n",
    "\n",
    "    u = np.cos(u) + 1j * np.sin(u)\n",
    "    # u = np.cos(u/n) + 1j * np.sin(u/n)\n",
    "    return u\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3456, 3456) (3456, 3456)\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "mass_matrix, energy_matrix = calc(bm, n, s= -1.0, lambda_t=0)\n",
    "u = np.random.rand(energy_matrix.shape[0]) + 1j * np.random.rand(energy_matrix.shape[0])\n",
    "eigvec = smallest_eigenvector_square_prefactored(energy_matrix, mass_matrix, 10, u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.+0.j 0.+0.j 0.+0.j ... 0.+0.j 0.+0.j 0.+0.j]\n",
      "Corresponding t value : 0.10051432414697475\n"
     ]
    }
   ],
   "source": [
    "u_aligned = smoothest_curvature_aligned(bm, mass_matrix, energy_matrix, n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.zeros(len(bm.verts)) + 1j * np.zeros(len(bm.verts))\n",
    "for v in bm.verts:\n",
    "    angle = bm.vertex_attributes[\"constrained_angles\"][v.index]\n",
    "    if not np.isnan(angle):\n",
    "        q[v.index] = np.cos(angle) + 1j * np.sin(angle)\n",
    "\n",
    "u = spsolve(energy_matrix, mass_matrix @ q)\n",
    "# eigvec = smallest_eigenvector_square_prefactored(energy_matrix, mass_matrix, 10, u, q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.234280737922546e-15\n"
     ]
    }
   ],
   "source": [
    "print(np.max(np.abs(energy_matrix @ u - mass_matrix@q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03305114, -0.38825986, -0.92095706],\n",
       "       [-0.50612555, -0.23600548,  0.82954104],\n",
       "       [-0.12101921, -0.99122142,  0.05323953],\n",
       "       ...,\n",
       "       [ 0.30122941,  0.95143064,  0.0635656 ],\n",
       "       [ 0.76459367,  0.03536108,  0.64354185],\n",
       "       [ 0.2597274 ,  0.71089186,  0.65358583]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rotate_axis_angle(vector, axis, angle):\n",
    "    angle = angle.reshape((-1,1))\n",
    "    vector = vector.reshape((-1,3))\n",
    "    axis = axis.reshape((-1,3))\n",
    "    c = np.cos(angle)\n",
    "    s = np.sin(angle)\n",
    "\n",
    "    axis = axis/np.linalg.norm(axis, axis=1)[:,None]\n",
    "    dot = np.einsum('ij,ij->i', axis, vector)[:,None] # fast dot product \n",
    "    xprod = np.cross(axis, vector)\n",
    "    # print(axis.shape, vector.shape, xprod.shape, dot.shape)\n",
    "    return (1-c) * dot * axis + c * vector + s * xprod\n",
    "\n",
    "all_X = []\n",
    "for i, v in enumerate(bm.verts):\n",
    "    he = bm.vertex_attributes[\"X\"][i]\n",
    "    X = np.array(he.twin.vertex.co - he.vertex.co)\n",
    "    X_perp = np.dot(X, v.normal)\n",
    "    X = X - X_perp * v.normal\n",
    "    all_X.append(X/np.linalg.norm(X))\n",
    "\n",
    "all_X = np.array(all_X)\n",
    "\n",
    "v_n = np.array([v.normal for v in bm.verts])\n",
    "vector_field = rotate_axis_angle(all_X, v_n, np.angle(u_aligned.ravel()))\n",
    "# vector_field = rotate_axis_angle(all_X, v_n, np.angle(u.ravel()))\n",
    "# vector_field = rotate_axis_angle(all_X, v_n, np.angle(eigvec.ravel()))\n",
    "\n",
    "attributes_to_delete = []\n",
    "for attr in mesh.attributes:\n",
    "    delete_attr = False\n",
    "    for s in [\"angle\", \"u_aligned\", \"X\", \"vf\", \"vector\", \"constrained\", \"e1\", \"field\"]:\n",
    "        if s in attr.name:\n",
    "            delete_attr = True\n",
    "            break\n",
    "    if delete_attr:\n",
    "        attributes_to_delete.append(attr)\n",
    "            \n",
    "for attr in attributes_to_delete:\n",
    "    try:\n",
    "        mesh.attributes.remove(attr)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "\n",
    "\n",
    "attr = mesh.attributes.new(name=\"vector_field\", type='FLOAT_VECTOR', domain='POINT')\n",
    "attr.data.foreach_set('vector', vector_field.flatten())\n",
    "vector_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_decomposition(original, grad, rot, harmonic):\n",
    "    \"\"\"\n",
    "    Validates the Hodge decomposition by checking orthogonality and reconstruction.\n",
    "\n",
    "    Parameters:\n",
    "    - original: Nx3 numpy array, the original vector field at each vertex.\n",
    "    - grad: Nx3 numpy array, the curl-free component (gradient).\n",
    "    - rot: Nx3 numpy array, the divergence-free component (rotational).\n",
    "    - harmonic: Nx3 numpy array, the harmonic component.\n",
    "\n",
    "    Returns:\n",
    "    - validation_results: dict, containing orthogonality and reconstruction checks.\n",
    "    \"\"\"\n",
    "    # Step 1: Compute dot products for orthogonality\n",
    "    grad_rot_orth = np.sum(np.sum(grad * rot, axis=1))  # Inner product of grad and rot\n",
    "    grad_harm_orth = np.sum(np.sum(grad * harmonic, axis=1))  # Inner product of grad and harmonic\n",
    "    rot_harm_orth = np.sum(np.sum(rot * harmonic, axis=1))  # Inner product of rot and harmonic\n",
    "\n",
    "    # Step 2: Check reconstruction\n",
    "    reconstructed = grad + rot + harmonic\n",
    "    reconstruction_error = np.linalg.norm(original - reconstructed) / np.linalg.norm(original)\n",
    "\n",
    "    # Step 3: Validate orthogonality (allow small numerical error)\n",
    "    orthogonality_tolerance = 1e-6\n",
    "    is_orthogonal = (\n",
    "        abs(grad_rot_orth) < orthogonality_tolerance and\n",
    "        abs(grad_harm_orth) < orthogonality_tolerance and\n",
    "        abs(rot_harm_orth) < orthogonality_tolerance\n",
    "    )\n",
    "\n",
    "    # Step 4: Store results in a dictionary\n",
    "    validation_results = {\n",
    "        \"is_orthogonal\": is_orthogonal,\n",
    "        \"grad_rot_dot\": grad_rot_orth,\n",
    "        \"grad_harm_dot\": grad_harm_orth,\n",
    "        \"rot_harm_dot\": rot_harm_orth,\n",
    "        \"reconstruction_error\": reconstruction_error,\n",
    "        \"reconstructed_matches_original\": reconstruction_error < orthogonality_tolerance,\n",
    "    }\n",
    "\n",
    "    return validation_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_orthogonal': False,\n",
       " 'grad_rot_dot': 37.661270754409884,\n",
       " 'grad_harm_dot': 23.317287532492003,\n",
       " 'rot_harm_dot': 8.602157222291803,\n",
       " 'reconstruction_error': 0.5370404794403703,\n",
       " 'reconstructed_matches_original': False}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solve_poisson(A, b):\n",
    "    # Solve the Poisson equation A x = b\n",
    "    return spsolve(A, b)\n",
    "\n",
    "d0, d1, hodge0, hodge1, hodge2 = bm.construct_dec_operators()\n",
    "hodge1_inv = bm._build_hodge1(inverse=True)\n",
    "# hodge1 = _build_hodge_star1_form(bm)\n",
    "one_form = bm.vector_field_to_1form(vector_field)\n",
    "\n",
    "# Curl-free Component\n",
    "laplace0 = d0.T @ hodge1 @ d0\n",
    "phi = solve_poisson(laplace0, d0.T @ hodge1 @ one_form)\n",
    "grad_component = d0 @ phi\n",
    "\n",
    "# Divergence-free Component\n",
    "laplace1 = d1 @ hodge1_inv @ d1.T\n",
    "psi = solve_poisson(laplace1, d1 @ one_form)\n",
    "rot_component = d1.T @ psi\n",
    "\n",
    "# Harmonic Component\n",
    "harmonic_component = one_form - grad_component - rot_component\n",
    "\n",
    "vector_grad = bm.one_form_to_vector_field(grad_component)\n",
    "vector_rot = bm.one_form_to_vector_field(rot_component)\n",
    "vector_harmonic = bm.one_form_to_vector_field(harmonic_component)\n",
    "\n",
    "\n",
    "validate_decomposition(vector_field, vector_grad, vector_rot, vector_harmonic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "one_form = bm.vector_field_to_1form(vector_field)\n",
    "\n",
    "vf = bm.one_form_to_vector_field(one_form)\n",
    "vf = vf/np.linalg.norm(vf, axis=1)[:,None]\n",
    "\n",
    "u = eigvec\n",
    "a = (np.angle(u.ravel())/n) \n",
    "a_aligned = (np.angle(u_aligned.ravel())/2) \n",
    "# field = np.cos(a) + 1j * np.sin(a)\n",
    "\n",
    "if 'X' in mesh.attributes:\n",
    "    mesh.attributes.remove(mesh.attributes[\"X\"])\n",
    "    mesh.attributes.remove(mesh.attributes[\"angle\"])\n",
    "    mesh.attributes.remove(mesh.attributes[\"u_aligned\"])\n",
    "    mesh.attributes.remove(mesh.attributes[\"vector_field\"])\n",
    "    mesh.attributes.remove(mesh.attributes[\"vf\"])\n",
    "    mesh.attributes.remove(mesh.attributes[\"vector_grad\"])\n",
    "    mesh.attributes.remove(mesh.attributes[\"vector_rot\"])\n",
    "    mesh.attributes.remove(mesh.attributes[\"vector_harmonic\"])\n",
    "\n",
    "for attr in mesh.attributes:\n",
    "    if attr.name.startswith(\"k1\") or attr.name.startswith(\"k2\"):\n",
    "        mesh.attributes.remove(attr)\n",
    "\n",
    "    \n",
    "attr = mesh.attributes.new(name=\"X\", type='FLOAT_VECTOR', domain='POINT')\n",
    "attr.data.foreach_set('vector', all_X.flatten())\n",
    "\n",
    "attr = mesh.attributes.new(name=\"angle\", type='FLOAT', domain='POINT')\n",
    "attr.data.foreach_set('value', a.flatten())\n",
    "    \n",
    "attr = mesh.attributes.new(name=\"u_aligned\", type='FLOAT', domain='POINT')\n",
    "attr.data.foreach_set('value', a_aligned.flatten())\n",
    "\n",
    "\n",
    "attr = mesh.attributes.new(name=\"vector_field\", type='FLOAT_VECTOR', domain='POINT')\n",
    "attr.data.foreach_set('vector', vector_field.flatten())\n",
    "\n",
    "attr = mesh.attributes.new(name=\"vf\", type='FLOAT_VECTOR', domain='POINT')\n",
    "attr.data.foreach_set('vector', vf.flatten())\n",
    "\n",
    "\n",
    "attr = mesh.attributes.new(name=\"vector_grad\", type='FLOAT_VECTOR', domain='POINT')\n",
    "attr.data.foreach_set('vector', vector_grad.flatten())\n",
    "\n",
    "\n",
    "attr = mesh.attributes.new(name=\"vector_rot\", type='FLOAT_VECTOR', domain='POINT')\n",
    "attr.data.foreach_set('vector', vector_rot.flatten())\n",
    "\n",
    "\n",
    "attr = mesh.attributes.new(name=\"vector_harmonic\", type='FLOAT_VECTOR', domain='POINT')\n",
    "attr.data.foreach_set('vector', vector_harmonic.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24946330261055633"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reconstruction_error = np.linalg.norm(vector_field - vf) / np.linalg.norm(vector_field)\n",
    "reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98635442, -0.13611538,  0.09261517],\n",
       "       [ 0.99421277, -0.07014715,  0.08136554],\n",
       "       [-0.06040013,  0.20938529, -0.975966  ],\n",
       "       ...,\n",
       "       [-0.03097116, -0.95756551,  0.28654681],\n",
       "       [-0.03894243, -0.98835976, -0.14706624],\n",
       "       [-0.99561312, -0.09246597,  0.01430224]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'axis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mcross(\u001b[43maxis\u001b[49m[\u001b[38;5;241m0\u001b[39m], vector[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'axis' is not defined"
     ]
    }
   ],
   "source": [
    "np.cross(axis[0], vector[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "def smallest_eigenvector_square(energy_matrix, mass_matrix, n_iterations):\n",
    "    \"\"\"\n",
    "    Compute the smallest eigenvector of the square using an iterative method.\n",
    "\n",
    "    Parameters:\n",
    "    - energy_matrix: Sparse energy matrix (scipy.sparse.csr_matrix)\n",
    "    - mass_matrix: Sparse mass matrix (scipy.sparse.csr_matrix)\n",
    "    - n_iterations: Number of iterations for the method.\n",
    "\n",
    "    Returns:\n",
    "    - x: Approximation of the smallest eigenvector.\n",
    "    \"\"\"\n",
    "    N = energy_matrix.shape[0]  # Number of rows\n",
    "    u = np.random.rand(N)       # Random initial vector\n",
    "    x = u.copy()                # Initialize x\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Solve the linear system: energy_matrix * x = mass_matrix * u\n",
    "        x = spsolve(energy_matrix, mass_matrix @ u)\n",
    "\n",
    "        # Re-normalize x with respect to the mass matrix\n",
    "        x = normalize(x, mass_matrix)\n",
    "\n",
    "        # Update u for the next iteration\n",
    "        u = x.copy()\n",
    "\n",
    "    return x\n",
    "\n",
    "def normalize(x, mass_matrix):\n",
    "    \"\"\"\n",
    "    Normalize vector x with respect to the mass matrix.\n",
    "    \"\"\"\n",
    "    norm = np.sqrt(x @ (mass_matrix @ x))  # Quadratic form norm\n",
    "    return x / norm if norm != 0 else x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse array of dtype 'complex128'\n",
       "\twith 13890 stored elements and shape (1986, 1986)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0396553-1.56941866e-14j -0.0396553+7.68617473e-15j\n",
      " -0.0396553+5.94654814e-15j ... -0.0396553-3.18584475e-12j\n",
      " -0.0396553+1.54463135e-13j -0.0396553+1.20815107e-14j]\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import spsolve\n",
    "import matplotlib.pyplot as plt\n",
    "def mysolve(mass_matrix, energy_matrix):\n",
    "\n",
    "    N = mass_matrix.shape[0]\n",
    "    u = np.random.rand(N)-.5 + 1j * (np.random.rand(N)-.5)\n",
    "\n",
    "    u = u/np.absolute(u)\n",
    "    norm_log = []\n",
    "    for i in range(50):\n",
    "        u = spsolve(energy_matrix, mass_matrix.dot(u))\n",
    "        # u = u / np.abs(u)\n",
    "        norm = np.sqrt(u @ (mass_matrix @ u))\n",
    "        norm_log.append(norm)\n",
    "        u = u/norm\n",
    "    print(energy_matrix.dot(u)/mass_matrix.dot(u))\n",
    "    norm_log = np.array(norm_log)\n",
    "    return norm_log\n",
    "norm_log = mysolve(mass_matrix, energy_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blender_4.3.1",
   "language": "python",
   "name": "blender_4.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
